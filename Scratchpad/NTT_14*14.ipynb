{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
    "import itertools\n",
    "import cmath\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,  12, 134, 112, 112, 112, 321, 321, 112, 112, 321, 112, 112, 321,\n",
      "         112, 112, 112, 111, 134, 321, 112, 321, 321, 112, 321, 112, 112, 321,\n",
      "         112, 321, 112, 112, 112, 111, 134,   2,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1]])\n",
      "tensor([[    0,    12,   134,   361,   973,  2929,  4268,   290,  8301,  3135,\n",
      "           508,  3557,   733,  2107,  7994,  8572,  7383,   973,  4059,   112,\n",
      "           508,   158,  8301,  2491,   973,   564,   321,  3135,  4034,   291,\n",
      "          2107,  5659,  1814,  8162,  6791,   111,   134,   158,   316,   158,\n",
      "          5595,  3490,  6121,   654,   564,  5553,  2929,  1510,   262,   564,\n",
      "          6791,  8060,  4034,   204,   195,  1814,  1718,  8162,  5169,  7004,\n",
      "          2843,   883,  6164,   706,  5595,   971,   365,  1510,  1132,   111,\n",
      "           134,    10,   361,   741,   973,   740,  2929,   385,  4268,   364,\n",
      "           290,   856,  8301,   821,  3135,  1368,   508,   939,  3557,  1236,\n",
      "           733,   449,  2107,   784,  7994,   475,  8572,   295,  7383,  1021,\n",
      "           973,   181,  4059,  2231,   112,   910,   508,   579,   158,   326,\n",
      "          8301,  1717,  2491,   748,   973,   885,   564,  3023,   321,  1423,\n",
      "          3135,   992,  4034, 27785,   291,   787,  2107,   849,  5659,    68,\n",
      "          1814,  7606,  8162, 37249,  6791,   111,   134,    10,   158,   741,\n",
      "           316,   740,   158,   385,  5595,   364,  3490,   856,  6121,   821,\n",
      "           654,  1368,   564,   939,  5553,  1236,  2929,   449,  1510,   784,\n",
      "           262,   475,   564,   295,  6791,  1021,  8060,   181,  4034,  2231,\n",
      "           204,   910,   195,   579,  1814,   326,  1718,  1717,  8162,   748,\n",
      "          5169,   885,  7004,  3023,  2843,  1423,   883,   992,  6164, 27785,\n",
      "           706,   787,  5595,   849,   971,    68,   365,  7606,  1510, 37249,\n",
      "          1132,   111,   134,    10,  1814,   741,   733,   740,  8403,   385,\n",
      "           379,   364,  3135,   856,  5169,   821,  7004,  1368,  2631,   939,\n",
      "          5545,  1236,  2843,   449,   361,   784,   231,   475,  8301,   295,\n",
      "           361,  1021,  1814,   181,   971,  2231,   204,   910,  3620,   579,\n",
      "           974,   326,  7694,  1717,  8572,   748,  7589,   885,   158,  3023,\n",
      "           321,  1423,  2107,   992,   155, 27785,  8403,   787,  3330,   849,\n",
      "          5169,    68,   291,  7606,   231, 37249,   132,   111,   134,   112,\n",
      "           321,   132,   132,   132,   155,   204,   155,   204,   195,   195,\n",
      "           155,   262,   262,   204,   231,   231,   204,   204,   204,   155,\n",
      "           132,   155,   132,   112,   132,   112,   321,   321,   321,   321,\n",
      "           321,   111,   134,   112,   321,   112,   112,   321,   112,   112,\n",
      "           112,   321,   321,   112,   112,   112,   321,   321,   321,   112,\n",
      "           112,   321,   112,   321,   321,   321,   112,   112,   321,   321,\n",
      "           112,   111,   134,     2,     1,     1,     1,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "def ntt_with_steps(sequence, prime, base):\n",
    "    n = len(sequence)\n",
    "    result = [0] * n\n",
    "    steps = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            result[i] += sequence[j] * pow(base, i * j, prime)\n",
    "        result[i] %= prime \n",
    "        steps.append(result[:i+1])\n",
    "    return result, steps\n",
    "\n",
    "\n",
    "\n",
    "def intt_with_steps(sequence, prime, root):\n",
    "    n = len(sequence)\n",
    "    result = [0] * n\n",
    "    steps = []\n",
    "    inv_root = pow(root, prime - 2, prime)\n",
    "    inv_n = pow(n, prime - 2, prime)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            result[i] += sequence[j] * pow(inv_root, i * j, prime)\n",
    "        result[i] = (result[i] * inv_n) % prime\n",
    "        steps.append(result[:i+1])  \n",
    "    return result, steps\n",
    "\n",
    "def detailed_intt_with_steps(sequence, prime, root):\n",
    "    n = len(sequence)\n",
    "    root_inv = pow(root, prime - 2, prime)  # Modular inverse of the root\n",
    "    n_inv = pow(n, prime - 2, prime)        # Modular inverse of n\n",
    "\n",
    "    def recursive_intt(a, depth=0):\n",
    "        n = len(a)\n",
    "        if n == 1:\n",
    "            return a, []\n",
    "        \n",
    "        a_even = a[0::2]\n",
    "        a_odd = a[1::2]\n",
    "\n",
    "        y_even, steps_even = recursive_intt(a_even, depth + 1)\n",
    "        y_odd, steps_odd = recursive_intt(a_odd, depth + 1)\n",
    "\n",
    "        root_pow = pow(root_inv, (prime - 1) // n, prime)\n",
    "        w = 1\n",
    "        y = [0] * n\n",
    "        combine_steps = []\n",
    "\n",
    "        for k in range(n // 2):\n",
    "            u = y_even[k] % prime\n",
    "            t = (y_odd[k] * w) % prime\n",
    "            y[k] = (u + t) % prime\n",
    "            y[k + n // 2] = (u - t) % prime\n",
    "            combine_steps.append([u, t, y[k], y[k + n // 2]])\n",
    "            w = (w * root_pow) % prime\n",
    "\n",
    "        # Include lower depth steps\n",
    "        # combine_steps =  combine_steps\n",
    "        combine_steps =  steps_even + steps_odd+ combine_steps\n",
    "        return y, combine_steps\n",
    "\n",
    "    final_result, combine_steps = recursive_intt(sequence)\n",
    "    normalized_result = [(x * n_inv) % prime for x in final_result]\n",
    "\n",
    "    combine_steps.append(final_result)\n",
    "    # combine_steps.append(normalized_result)\n",
    "\n",
    "    # Return all combined steps, raw results, and normalized results as a list\n",
    "    return normalized_result, combine_steps\n",
    "\n",
    "class NTTDataset(Dataset):\n",
    "    def __init__(self, size=1000, num_bits=4, prime=17,root=3, tokenizer=None, max_length=300, used_data=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.prime = prime\n",
    "        self.root = root\n",
    "        self.num_bits = num_bits\n",
    "        self.data = []\n",
    "\n",
    "        while len(self.data) < size:\n",
    "            seq1 = tuple(np.random.randint(0, 2, num_bits).tolist())\n",
    "            seq2 = tuple(np.random.randint(0, 2, num_bits).tolist())\n",
    "            if used_data is None or (seq1, seq2) not in used_data:\n",
    "                self.data.append((seq1, seq2))\n",
    "                if used_data is not None:\n",
    "                    used_data.add((seq1, seq2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq1, seq2 = self.data[idx]\n",
    "        reversed_seq1 = seq1[::-1]\n",
    "        reversed_seq2 = seq2[::-1]\n",
    "        padded_seq1 = reversed_seq1 + (0,) * (32 -len(seq1))\n",
    "        padded_seq2 = reversed_seq2 + (0,) * (32 - len(seq2))\n",
    "\n",
    "\n",
    "        even_indices_seq = padded_seq1[0::2]\n",
    "        odd_indices_seq = padded_seq1[1::2]\n",
    "\n",
    "        even_indices_seq2 = even_indices_seq[0::2]\n",
    "        odd_indices_seq2 = odd_indices_seq[1::2]\n",
    "\n",
    "        even_indices_seq3 = even_indices_seq2[0::2]\n",
    "        odd_indices_seq3 = odd_indices_seq2[1::2]\n",
    "\n",
    "        # Calculate NTT of even and odd indices\n",
    "        ntt_even = sympy.ntt(even_indices_seq, self.prime)\n",
    "        ntt_odd = sympy.ntt(odd_indices_seq, self.prime)\n",
    "        ntt_even2 = sympy.ntt(even_indices_seq2, self.prime)\n",
    "        ntt_odd2 = sympy.ntt(odd_indices_seq2, self.prime)\n",
    "        ntt_even3 = sympy.ntt(even_indices_seq3, self.prime)\n",
    "        ntt_odd3 = sympy.ntt(odd_indices_seq3, self.prime)\n",
    "\n",
    "        ntt = sympy.ntt(padded_seq1, self.prime)\n",
    "        ntt2 = sympy.ntt(padded_seq2, self.prime)\n",
    "        \n",
    "        ntt_res1, ntt_steps1 = ntt_with_steps(padded_seq1, self.prime, self.root)\n",
    "        ntt_res2, ntt_steps2 = ntt_with_steps(padded_seq2, self.prime, self.root)\n",
    "        \n",
    "\n",
    "        flattened_steps = []\n",
    "        \n",
    "        # flattened_steps.extend(padded_seq1)\n",
    "        # flattened_steps.append(-1)\n",
    "        # flattened_steps.extend(padded_seq2)\n",
    "        # flattened_steps.append(-1)\n",
    "        # for step1, step2 in zip(ntt_steps1, ntt_steps2):\n",
    "        #     flattened_steps.extend(step1)\n",
    "        #     flattened_steps.extend(step2)\n",
    "        #     flattened_steps.append(-1)\n",
    "        flattened_steps.append(-1)\n",
    "       \n",
    "        flattened_steps.extend(ntt)\n",
    "        flattened_steps.append(-1)\n",
    "        flattened_steps.extend(ntt2)\n",
    "        flattened_steps.append(-1)\n",
    "        \n",
    "        last_step1 = ntt_steps1[-1]\n",
    "        last_step2 = ntt_steps2[-1]\n",
    "\n",
    "\n",
    "        \n",
    "        flattened_steps.append(''.join(f\"{i} {x} \" for i, x in zip('abcdefghijklmnopqrstuvwxyz!@#$%^',ntt)) + \"-1 \" +\n",
    "                               ''.join(f\"{i} {x} \" for i, x in zip('abcdefghijklmnopqrstuvwxyz!@#$%^!@#$%^', ntt2)) + \"-1\")\n",
    "        pointwise_mult = [((a * b) % self.prime) for a, b in zip(ntt, ntt2)]\n",
    "        pointwise_mult_mod = [((a * b) % self.prime) for a, b in zip(ntt, ntt2)]\n",
    "        flattened_steps.append(' '.join(f\"{i} {x}\" for i, x in zip('abcdefghijklmnopqrstuvwxyz!@#$%^!@#$%^', pointwise_mult)))\n",
    "        flattened_steps.append(-1)\n",
    "        # flattened_steps.extend(pointwise_mult)\n",
    "        # flattened_steps.append(-1)\n",
    "        # flattened_steps.extend(pointwise_mult_mod)\n",
    "        # flattened_steps.append(-1)\n",
    "        \n",
    "        # inverse, intt_steps = detailed_intt_with_steps(pointwise_mult, self.prime, self.root)\n",
    "        # for step in intt_steps:\n",
    "        #     flattened_steps.extend(step)\n",
    "        #     flattened_steps.append(-1)\n",
    "        inverse = sympy.intt(pointwise_mult, self.prime)\n",
    "\n",
    "        flattened_steps.extend(inverse)\n",
    "        flattened_steps.append(-1)\n",
    "\n",
    "        result = sum([inverse[i] * 2 ** i for i in range(len(inverse))])\n",
    "        binary_result = bin(result)[2:].zfill(2 * self.num_bits)\n",
    "\n",
    "        flattened_steps.append(' '.join(f\"{i}\" for i in binary_result))\n",
    "        flattened_steps.append(-1)\n",
    "        \n",
    "        combined_input = (-1,) + seq1 + (-1,) + seq2 + (-1,)\n",
    "        input_text = ' '.join(map(str, combined_input))\n",
    "        target_text = ' '.join(map(str, flattened_steps))\n",
    "\n",
    "        # print(input_text)\n",
    "        # print(target_text)\n",
    "        \n",
    "        inputs = self.tokenizer(input_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        targets = self.tokenizer(target_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        inputs = {k: v.squeeze() for k, v in inputs.items()}\n",
    "        targets = {k: v.squeeze() for k, v in targets.items()}\n",
    "        \n",
    "        inputs['labels'] = targets['input_ids']\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "# Generate data\n",
    "used_data = set()\n",
    "train_dataset = NTTDataset(size=5000000, num_bits=14, prime=97,root=5, tokenizer=tokenizer, max_length=340, used_data=used_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Create OOD dataset\n",
    "ood_dataset = NTTDataset(size=10000, num_bits=14, prime=97,root=5, tokenizer=tokenizer, max_length=340, used_data=used_data)\n",
    "ood_dataloader = DataLoader(ood_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Example usage\n",
    "for batch in train_dataloader:\n",
    "    print(batch['input_ids'])\n",
    "    break\n",
    "\n",
    "for batch in ood_dataloader:\n",
    "    print(batch['labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50265, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartConfig\n",
    "config = BartConfig(\n",
    "    encoder_layers=1,\n",
    "    encoder_ffn_dim=2,\n",
    "    encoder_attention_heads=1,\n",
    "    decoder_layers=2,\n",
    "    decoder_ffn_dim=4096,\n",
    "    decoder_attention_heads=2,\n",
    "    d_model=1024,\n",
    ")\n",
    "\n",
    "model = BartForConditionalGeneration(config)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Get the token predictions by taking the argmax of the logits along the last dimension\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Replace -100 in labels as it is the padding index and shouldn't be counted in the accuracy\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    # Iterate over predictions and labels\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        # Trim padding tokens (assuming padding token is tokenizer.pad_token_id, usually 1 or 0)\n",
    "        # pred_trimmed = pred[pred != tokenizer.pad_token_id]\n",
    "        # label_trimmed = label[label != tokenizer.pad_token_id]\n",
    "\n",
    "        # # Ensure both prediction and label are of the same length after trimming\n",
    "        # min_len = min(len(pred_trimmed), len(label_trimmed))\n",
    "        # pred_trimmed = pred_trimmed[:min_len]\n",
    "        # label_trimmed = label_trimmed[:min_len]\n",
    "\n",
    "        # Check if the trimmed sequences match\n",
    "        if np.array_equal(pred, label):\n",
    "            correct += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../../../scratch/aabavandpour/14*14/results',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=200,\n",
    "    gradient_accumulation_steps=4,\n",
    "    tf32=True,\n",
    "    dataloader_num_workers=8,\n",
    "    evaluation_strategy=\"steps\",  # Evaluate every `eval_steps`\n",
    "    eval_steps=200,  # How often to run evaluation\n",
    "    learning_rate=0.00001\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=ood_dataset,\n",
    "    # compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6059\n",
      "6060\n",
      "6061\n",
      "6062\n",
      "6063\n",
      "6064\n",
      "6065\n",
      "6066\n",
      "6067\n",
      "6068\n",
      "6069\n",
      "6070\n",
      "6071\n",
      "6072\n",
      "6073\n",
      "6074\n",
      "6075\n",
      "6076\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6087\n",
      "6088\n",
      "6089\n",
      "6090\n",
      "6091\n",
      "6092\n",
      "6093\n",
      "6094\n",
      "6095\n",
      "6096\n",
      "6097\n",
      "6098\n",
      "6099\n",
      "6100\n",
      "6101\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6112\n",
      "6113\n",
      "6114\n",
      "6115\n",
      "6116\n",
      "6117\n",
      "6118\n",
      "6119\n",
      "6120\n",
      "6121\n",
      "6122\n",
      "6123\n",
      "6124\n",
      "6125\n",
      "6126\n",
      "6127\n",
      "6128\n",
      "6129\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6145\n",
      "6146\n",
      "6147\n",
      "6148\n",
      "6149\n",
      "6150\n",
      "6151\n",
      "6152\n",
      "6153\n",
      "6154\n",
      "6155\n",
      "6156\n",
      "6157\n",
      "6158\n",
      "6159\n",
      "6160\n",
      "6161\n",
      "6162\n",
      "6163\n",
      "6164\n",
      "6165\n",
      "6166\n",
      "6167\n",
      "6168\n",
      "6169\n",
      "6170\n",
      "6171\n",
      "6172\n",
      "6173\n",
      "6174\n",
      "6175\n",
      "6176\n",
      "6177\n",
      "6178\n",
      "6179\n",
      "6180\n",
      "6181\n",
      "6182\n",
      "6183\n",
      "6184\n",
      "6185\n",
      "6186\n",
      "6187\n",
      "6188\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6230\n",
      "6231\n",
      "6232\n",
      "6233\n",
      "6234\n",
      "6235\n",
      "6236\n",
      "6237\n",
      "6238\n",
      "6239\n",
      "6240\n",
      "6241\n",
      "6242\n",
      "6243\n",
      "6244\n",
      "6245\n",
      "6246\n",
      "6247\n",
      "6248\n",
      "6249\n",
      "6250\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n",
      "6304\n",
      "6305\n",
      "6306\n",
      "6307\n",
      "6308\n",
      "6309\n",
      "6310\n",
      "6311\n",
      "6312\n",
      "6313\n",
      "6314\n",
      "6315\n",
      "6316\n",
      "6317\n",
      "6318\n",
      "6319\n",
      "6320\n",
      "6321\n",
      "6322\n",
      "6323\n",
      "6324\n",
      "6325\n",
      "6326\n",
      "6327\n",
      "6328\n",
      "6329\n",
      "6330\n",
      "6331\n",
      "6332\n",
      "6333\n",
      "6334\n",
      "6335\n",
      "6336\n",
      "6337\n",
      "6338\n",
      "6339\n",
      "6340\n",
      "6341\n",
      "6342\n",
      "6343\n",
      "6344\n",
      "6345\n",
      "6346\n",
      "6347\n",
      "6348\n",
      "6349\n",
      "6350\n",
      "6351\n",
      "6352\n",
      "6353\n",
      "6354\n",
      "6355\n",
      "6356\n",
      "6357\n",
      "6358\n",
      "6359\n",
      "6360\n",
      "6361\n",
      "6362\n",
      "6363\n",
      "6364\n",
      "6365\n",
      "6366\n",
      "6367\n",
      "6368\n",
      "6369\n",
      "6370\n",
      "6371\n",
      "6372\n",
      "6373\n",
      "6374\n",
      "6375\n",
      "6376\n",
      "6377\n",
      "6378\n",
      "6379\n",
      "6380\n",
      "6381\n",
      "6382\n",
      "6383\n",
      "6384\n",
      "6385\n",
      "6386\n",
      "6387\n",
      "6388\n",
      "6389\n",
      "6390\n",
      "6391\n",
      "6392\n",
      "6393\n",
      "6394\n",
      "6395\n",
      "6396\n",
      "6397\n",
      "6398\n",
      "6399\n",
      "6400\n",
      "6401\n",
      "6402\n",
      "6403\n",
      "6404\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6408\n",
      "6409\n",
      "6410\n",
      "6411\n",
      "6412\n",
      "6413\n",
      "6414\n",
      "6415\n",
      "6416\n",
      "6417\n",
      "6418\n",
      "6419\n",
      "6420\n",
      "6421\n",
      "6422\n",
      "6423\n",
      "6424\n",
      "6425\n",
      "6426\n",
      "6427\n",
      "6428\n",
      "6429\n",
      "6430\n",
      "6431\n",
      "6432\n",
      "6433\n",
      "6434\n",
      "6435\n",
      "6436\n",
      "6437\n",
      "6438\n",
      "6439\n",
      "6440\n",
      "6441\n",
      "6442\n",
      "6443\n",
      "6444\n",
      "6445\n",
      "6446\n",
      "6447\n",
      "6448\n",
      "6449\n",
      "6450\n",
      "6451\n",
      "6452\n",
      "6453\n",
      "6454\n",
      "6455\n",
      "6456\n",
      "6457\n",
      "6458\n",
      "6459\n",
      "6460\n",
      "6461\n",
      "6462\n",
      "6463\n",
      "6464\n",
      "6465\n",
      "6466\n",
      "6467\n",
      "6468\n",
      "6469\n",
      "6470\n",
      "6471\n",
      "6472\n",
      "6473\n",
      "6474\n",
      "6475\n",
      "6476\n",
      "6477\n",
      "6478\n",
      "6479\n",
      "6480\n",
      "6481\n",
      "6482\n",
      "6483\n",
      "6484\n",
      "6485\n",
      "6486\n",
      "6487\n",
      "6488\n",
      "6489\n",
      "6490\n",
      "6491\n",
      "6492\n",
      "6493\n",
      "6494\n",
      "6495\n",
      "6496\n",
      "6497\n",
      "6498\n",
      "6499\n",
      "6500\n",
      "6501\n",
      "6502\n",
      "6503\n",
      "6504\n",
      "6505\n",
      "6506\n",
      "6507\n",
      "6508\n",
      "6509\n",
      "6510\n",
      "6511\n",
      "6512\n",
      "6513\n",
      "6514\n",
      "6515\n",
      "6516\n",
      "6517\n",
      "6518\n",
      "6519\n",
      "6520\n",
      "6521\n",
      "6522\n",
      "6523\n",
      "6524\n",
      "6525\n",
      "6526\n",
      "6527\n",
      "6528\n",
      "6529\n",
      "6530\n",
      "6531\n",
      "6532\n",
      "6533\n",
      "6534\n",
      "6535\n",
      "6536\n",
      "6537\n",
      "6538\n",
      "6539\n",
      "6540\n",
      "6541\n",
      "6542\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6546\n",
      "6547\n",
      "6548\n",
      "6549\n",
      "6550\n",
      "6551\n",
      "6552\n",
      "6553\n",
      "6554\n",
      "6555\n",
      "6556\n",
      "6557\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6561\n",
      "6562\n",
      "6563\n",
      "6564\n",
      "6565\n",
      "6566\n",
      "6567\n",
      "6568\n",
      "6569\n",
      "6570\n",
      "6571\n",
      "6572\n",
      "6573\n",
      "6574\n",
      "6575\n",
      "6576\n",
      "6577\n",
      "6578\n",
      "6579\n",
      "6580\n",
      "6581\n",
      "6582\n",
      "6583\n",
      "6584\n",
      "6585\n",
      "6586\n",
      "6587\n",
      "6588\n",
      "6589\n",
      "6590\n",
      "6591\n",
      "6592\n",
      "6593\n",
      "6594\n",
      "6595\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6599\n",
      "6600\n",
      "6601\n",
      "6602\n",
      "6603\n",
      "6604\n",
      "6605\n",
      "6606\n",
      "6607\n",
      "6608\n",
      "6609\n",
      "6610\n",
      "6611\n",
      "6612\n",
      "6613\n",
      "6614\n",
      "6615\n",
      "6616\n",
      "6617\n",
      "6618\n",
      "6619\n",
      "6620\n",
      "6621\n",
      "6622\n",
      "6623\n",
      "6624\n",
      "6625\n",
      "6626\n",
      "6627\n",
      "6628\n",
      "6629\n",
      "6630\n",
      "6631\n",
      "6632\n",
      "6633\n",
      "6634\n",
      "6635\n",
      "6636\n",
      "6637\n",
      "6638\n",
      "6639\n",
      "6640\n",
      "6641\n",
      "6642\n",
      "6643\n",
      "6644\n",
      "6645\n",
      "6646\n",
      "6647\n",
      "6648\n",
      "6649\n",
      "6650\n",
      "6651\n",
      "6652\n",
      "6653\n",
      "6654\n",
      "6655\n",
      "6656\n",
      "6657\n",
      "6658\n",
      "6659\n",
      "6660\n",
      "6661\n",
      "6662\n",
      "6663\n",
      "6664\n",
      "6665\n",
      "6666\n",
      "6667\n",
      "6668\n",
      "6669\n",
      "6670\n",
      "6671\n",
      "6672\n",
      "6673\n",
      "6674\n",
      "6675\n",
      "6676\n",
      "6677\n",
      "6678\n",
      "6679\n",
      "6680\n",
      "6681\n",
      "6682\n",
      "6683\n",
      "6684\n",
      "6685\n",
      "6686\n",
      "6687\n",
      "6688\n",
      "6689\n",
      "6690\n",
      "6691\n",
      "6692\n",
      "6693\n",
      "6694\n",
      "6695\n",
      "6696\n",
      "6697\n",
      "6698\n",
      "6699\n",
      "6700\n",
      "6701\n",
      "6702\n",
      "6703\n",
      "6704\n",
      "6705\n",
      "6706\n",
      "6707\n",
      "6708\n",
      "6709\n",
      "6710\n",
      "6711\n",
      "6712\n",
      "6713\n",
      "6714\n",
      "6715\n",
      "6716\n",
      "6717\n",
      "6718\n",
      "6719\n",
      "6720\n",
      "6721\n",
      "6722\n",
      "6723\n",
      "6724\n",
      "6725\n",
      "6726\n",
      "6727\n",
      "6728\n",
      "6729\n",
      "6730\n",
      "6731\n",
      "6732\n",
      "6733\n",
      "6734\n",
      "6735\n",
      "6736\n",
      "6737\n",
      "6738\n",
      "6739\n",
      "6740\n",
      "6741\n",
      "6742\n",
      "6743\n",
      "6744\n",
      "6745\n",
      "6746\n",
      "6747\n",
      "6748\n",
      "6749\n",
      "6750\n",
      "6751\n",
      "6752\n",
      "6753\n",
      "6754\n",
      "6755\n",
      "6756\n",
      "6757\n",
      "6758\n",
      "6759\n",
      "6760\n",
      "6761\n",
      "6762\n",
      "6763\n",
      "6764\n",
      "6765\n",
      "6766\n",
      "6767\n",
      "6768\n",
      "6769\n",
      "6770\n",
      "6771\n",
      "6772\n",
      "6773\n",
      "6774\n",
      "6775\n",
      "6776\n",
      "6777\n",
      "6778\n",
      "6779\n",
      "6780\n",
      "6781\n",
      "6782\n",
      "6783\n",
      "6784\n",
      "6785\n",
      "6786\n",
      "6787\n",
      "6788\n",
      "6789\n",
      "6790\n",
      "6791\n",
      "6792\n",
      "6793\n",
      "6794\n",
      "6795\n",
      "6796\n",
      "6797\n",
      "6798\n",
      "6799\n",
      "6800\n",
      "6801\n",
      "6802\n",
      "6803\n",
      "6804\n",
      "6805\n",
      "6806\n",
      "6807\n",
      "6808\n",
      "6809\n",
      "6810\n",
      "6811\n",
      "6812\n",
      "6813\n",
      "6814\n",
      "6815\n",
      "6816\n",
      "6817\n",
      "6818\n",
      "6819\n",
      "6820\n",
      "6821\n",
      "6822\n",
      "6823\n",
      "6824\n",
      "6825\n",
      "6826\n",
      "6827\n",
      "6828\n",
      "6829\n",
      "6830\n",
      "6831\n",
      "6832\n",
      "6833\n",
      "6834\n",
      "6835\n",
      "6836\n",
      "6837\n",
      "6838\n",
      "6839\n",
      "6840\n",
      "6841\n",
      "6842\n",
      "6843\n",
      "6844\n",
      "6845\n",
      "6846\n",
      "6847\n",
      "6848\n",
      "6849\n",
      "6850\n",
      "6851\n",
      "6852\n",
      "6853\n",
      "6854\n",
      "6855\n",
      "6856\n",
      "6857\n",
      "6858\n",
      "6859\n",
      "6860\n",
      "6861\n",
      "6862\n",
      "6863\n",
      "6864\n",
      "6865\n",
      "6866\n",
      "6867\n",
      "6868\n",
      "6869\n",
      "6870\n",
      "6871\n",
      "6872\n",
      "6873\n",
      "6874\n",
      "6875\n",
      "6876\n",
      "6877\n",
      "6878\n",
      "6879\n",
      "6880\n",
      "6881\n",
      "6882\n",
      "6883\n",
      "6884\n",
      "6885\n",
      "6886\n",
      "6887\n",
      "6888\n",
      "6889\n",
      "6890\n",
      "6891\n",
      "6892\n",
      "6893\n",
      "6894\n",
      "6895\n",
      "6896\n",
      "6897\n",
      "6898\n",
      "6899\n",
      "6900\n",
      "6901\n",
      "6902\n",
      "6903\n",
      "6904\n",
      "6905\n",
      "6906\n",
      "6907\n",
      "6908\n",
      "6909\n",
      "6910\n",
      "6911\n",
      "6912\n",
      "6913\n",
      "6914\n",
      "6915\n",
      "6916\n",
      "6917\n",
      "6918\n",
      "6919\n",
      "6920\n",
      "6921\n",
      "6922\n",
      "6923\n",
      "6924\n",
      "6925\n",
      "6926\n",
      "6927\n",
      "6928\n",
      "6929\n",
      "6930\n",
      "6931\n",
      "6932\n",
      "6933\n",
      "6934\n",
      "6935\n",
      "6936\n",
      "6937\n",
      "6938\n",
      "6939\n",
      "6940\n",
      "6941\n",
      "6942\n",
      "6943\n",
      "6944\n",
      "6945\n",
      "6946\n",
      "6947\n",
      "6948\n",
      "6949\n",
      "6950\n",
      "6951\n",
      "6952\n",
      "6953\n",
      "6954\n",
      "6955\n",
      "6956\n",
      "6957\n",
      "6958\n",
      "6959\n",
      "6960\n",
      "6961\n",
      "6962\n",
      "6963\n",
      "6964\n",
      "6965\n",
      "6966\n",
      "6967\n",
      "6968\n",
      "6969\n",
      "6970\n",
      "6971\n",
      "6972\n",
      "6973\n",
      "6974\n",
      "6975\n",
      "6976\n",
      "6977\n",
      "6978\n",
      "6979\n",
      "6980\n",
      "6981\n",
      "6982\n",
      "6983\n",
      "6984\n",
      "6985\n",
      "6986\n",
      "6987\n",
      "6988\n",
      "6989\n",
      "6990\n",
      "6991\n",
      "6992\n",
      "6993\n",
      "6994\n",
      "6995\n",
      "6996\n",
      "6997\n",
      "6998\n",
      "6999\n",
      "7000\n",
      "7001\n",
      "7002\n",
      "7003\n",
      "7004\n",
      "7005\n",
      "7006\n",
      "7007\n",
      "7008\n",
      "7009\n",
      "7010\n",
      "7011\n",
      "7012\n",
      "7013\n",
      "7014\n",
      "7015\n",
      "7016\n",
      "7017\n",
      "7018\n",
      "7019\n",
      "7020\n",
      "7021\n",
      "7022\n",
      "7023\n",
      "7024\n",
      "7025\n",
      "7026\n",
      "7027\n",
      "7028\n",
      "7029\n",
      "7030\n",
      "7031\n",
      "7032\n",
      "7033\n",
      "7034\n",
      "7035\n",
      "7036\n",
      "7037\n",
      "7038\n",
      "7039\n",
      "7040\n",
      "7041\n",
      "7042\n",
      "7043\n",
      "7044\n",
      "7045\n",
      "7046\n",
      "7047\n",
      "7048\n",
      "7049\n",
      "7050\n",
      "7051\n",
      "7052\n",
      "7053\n",
      "7054\n",
      "7055\n",
      "7056\n",
      "7057\n",
      "7058\n",
      "7059\n",
      "7060\n",
      "7061\n",
      "7062\n",
      "7063\n",
      "7064\n",
      "7065\n",
      "7066\n",
      "7067\n",
      "7068\n",
      "7069\n",
      "7070\n",
      "7071\n",
      "7072\n",
      "7073\n",
      "7074\n",
      "7075\n",
      "7076\n",
      "7077\n",
      "7078\n",
      "7079\n",
      "7080\n",
      "7081\n",
      "7082\n",
      "7083\n",
      "7084\n",
      "7085\n",
      "7086\n",
      "7087\n",
      "7088\n",
      "7089\n",
      "7090\n",
      "7091\n",
      "7092\n",
      "7093\n",
      "7094\n",
      "7095\n",
      "7096\n",
      "7097\n",
      "7098\n",
      "7099\n",
      "7100\n",
      "7101\n",
      "7102\n",
      "7103\n",
      "7104\n",
      "7105\n",
      "7106\n",
      "7107\n",
      "7108\n",
      "7109\n",
      "7110\n",
      "7111\n",
      "7112\n",
      "7113\n",
      "7114\n",
      "7115\n",
      "7116\n",
      "7117\n",
      "7118\n",
      "7119\n",
      "7120\n",
      "7121\n",
      "7122\n",
      "7123\n",
      "7124\n",
      "7125\n",
      "7126\n",
      "7127\n",
      "7128\n",
      "7129\n",
      "7130\n",
      "7131\n",
      "7132\n",
      "7133\n",
      "7134\n",
      "7135\n",
      "7136\n",
      "7137\n",
      "7138\n",
      "7139\n",
      "7140\n",
      "7141\n",
      "7142\n",
      "7143\n",
      "7144\n",
      "7145\n",
      "7146\n",
      "7147\n",
      "7148\n",
      "7149\n",
      "7150\n",
      "7151\n",
      "7152\n",
      "7153\n",
      "7154\n",
      "7155\n",
      "7156\n",
      "7157\n",
      "7158\n",
      "7159\n",
      "7160\n",
      "7161\n",
      "7162\n",
      "7163\n",
      "7164\n",
      "7165\n",
      "7166\n",
      "7167\n",
      "7168\n",
      "7169\n",
      "7170\n",
      "7171\n",
      "7172\n",
      "7173\n",
      "7174\n",
      "7175\n",
      "7176\n",
      "7177\n",
      "7178\n",
      "7179\n",
      "7180\n",
      "7181\n",
      "7182\n",
      "7183\n",
      "7184\n",
      "7185\n",
      "7186\n",
      "7187\n",
      "7188\n",
      "7189\n",
      "7190\n",
      "7191\n",
      "7192\n",
      "7193\n",
      "7194\n",
      "7195\n",
      "7196\n",
      "7197\n",
      "7198\n",
      "7199\n",
      "7200\n",
      "7201\n",
      "7202\n",
      "7203\n",
      "7204\n",
      "7205\n",
      "7206\n",
      "7207\n",
      "7208\n",
      "7209\n",
      "7210\n",
      "7211\n",
      "7212\n",
      "7213\n",
      "7214\n",
      "7215\n",
      "7216\n",
      "7217\n",
      "7218\n",
      "7219\n",
      "7220\n",
      "7221\n",
      "7222\n",
      "7223\n",
      "7224\n",
      "7225\n",
      "7226\n",
      "7227\n",
      "7228\n",
      "7229\n",
      "7230\n",
      "7231\n",
      "7232\n",
      "7233\n",
      "7234\n",
      "7235\n",
      "7236\n",
      "7237\n",
      "7238\n",
      "7239\n",
      "7240\n",
      "7241\n",
      "7242\n",
      "7243\n",
      "7244\n",
      "7245\n",
      "7246\n",
      "7247\n",
      "7248\n",
      "7249\n",
      "7250\n",
      "7251\n",
      "7252\n",
      "7253\n",
      "7254\n",
      "7255\n",
      "7256\n",
      "7257\n",
      "7258\n",
      "7259\n",
      "7260\n",
      "7261\n",
      "7262\n",
      "7263\n",
      "7264\n",
      "7265\n",
      "7266\n",
      "7267\n",
      "7268\n",
      "7269\n",
      "7270\n",
      "7271\n",
      "7272\n",
      "7273\n",
      "7274\n",
      "7275\n",
      "7276\n",
      "7277\n",
      "7278\n",
      "7279\n",
      "7280\n",
      "7281\n",
      "7282\n",
      "7283\n",
      "7284\n",
      "7285\n",
      "7286\n",
      "7287\n",
      "7288\n",
      "7289\n",
      "7290\n",
      "7291\n",
      "7292\n",
      "7293\n",
      "7294\n",
      "7295\n",
      "7296\n",
      "7297\n",
      "7298\n",
      "7299\n",
      "7300\n",
      "7301\n",
      "7302\n",
      "7303\n",
      "7304\n",
      "7305\n",
      "7306\n",
      "7307\n",
      "7308\n",
      "7309\n",
      "7310\n",
      "7311\n",
      "7312\n",
      "7313\n",
      "7314\n",
      "7315\n",
      "7316\n",
      "7317\n",
      "7318\n",
      "7319\n",
      "7320\n",
      "7321\n",
      "7322\n",
      "7323\n",
      "7324\n",
      "7325\n",
      "7326\n",
      "7327\n",
      "7328\n",
      "7329\n",
      "7330\n",
      "7331\n",
      "7332\n",
      "7333\n",
      "7334\n",
      "7335\n",
      "7336\n",
      "7337\n",
      "7338\n",
      "7339\n",
      "7340\n",
      "7341\n",
      "7342\n",
      "7343\n",
      "7344\n",
      "7345\n",
      "7346\n",
      "7347\n",
      "7348\n",
      "7349\n",
      "7350\n",
      "7351\n",
      "7352\n",
      "7353\n",
      "7354\n",
      "7355\n",
      "7356\n",
      "7357\n",
      "7358\n",
      "7359\n",
      "7360\n",
      "7361\n",
      "7362\n",
      "7363\n",
      "7364\n",
      "7365\n",
      "7366\n",
      "7367\n",
      "7368\n",
      "7369\n",
      "7370\n",
      "7371\n",
      "7372\n",
      "7373\n",
      "7374\n",
      "7375\n",
      "7376\n",
      "7377\n",
      "7378\n",
      "7379\n",
      "7380\n",
      "7381\n",
      "7382\n",
      "7383\n",
      "7384\n",
      "7385\n",
      "7386\n",
      "7387\n",
      "7388\n",
      "7389\n",
      "7390\n",
      "7391\n",
      "7392\n",
      "7393\n",
      "7394\n",
      "7395\n",
      "7396\n",
      "7397\n",
      "7398\n",
      "7399\n",
      "7400\n",
      "7401\n",
      "7402\n",
      "7403\n",
      "7404\n",
      "7405\n",
      "7406\n",
      "7407\n",
      "7408\n",
      "7409\n",
      "7410\n",
      "7411\n",
      "7412\n",
      "7413\n",
      "7414\n",
      "7415\n",
      "7416\n",
      "7417\n",
      "7418\n",
      "7419\n",
      "7420\n",
      "7421\n",
      "7422\n",
      "7423\n",
      "7424\n",
      "7425\n",
      "7426\n",
      "7427\n",
      "7428\n",
      "7429\n",
      "7430\n",
      "7431\n",
      "7432\n",
      "7433\n",
      "7434\n",
      "7435\n",
      "7436\n",
      "7437\n",
      "7438\n",
      "7439\n",
      "7440\n",
      "7441\n",
      "7442\n",
      "7443\n",
      "7444\n",
      "7445\n",
      "7446\n",
      "7447\n",
      "7448\n",
      "7449\n",
      "7450\n",
      "7451\n",
      "7452\n",
      "7453\n",
      "7454\n",
      "7455\n",
      "7456\n",
      "7457\n",
      "7458\n",
      "7459\n",
      "7460\n",
      "7461\n",
      "7462\n",
      "7463\n",
      "7464\n",
      "7465\n",
      "7466\n",
      "7467\n",
      "7468\n",
      "7469\n",
      "7470\n",
      "7471\n",
      "7472\n",
      "7473\n",
      "7474\n",
      "7475\n",
      "7476\n",
      "7477\n",
      "7478\n",
      "7479\n",
      "7480\n",
      "7481\n",
      "7482\n",
      "7483\n",
      "7484\n",
      "7485\n",
      "7486\n",
      "7487\n",
      "7488\n",
      "7489\n",
      "7490\n",
      "7491\n",
      "7492\n",
      "7493\n",
      "7494\n",
      "7495\n",
      "7496\n",
      "7497\n",
      "7498\n",
      "7499\n",
      "7500\n",
      "7501\n",
      "7502\n",
      "7503\n",
      "7504\n",
      "7505\n",
      "7506\n",
      "7507\n",
      "7508\n",
      "7509\n",
      "7510\n",
      "7511\n",
      "7512\n",
      "7513\n",
      "7514\n",
      "7515\n",
      "7516\n",
      "7517\n",
      "7518\n",
      "7519\n",
      "7520\n",
      "7521\n",
      "7522\n",
      "7523\n",
      "7524\n",
      "7525\n",
      "7526\n",
      "7527\n",
      "7528\n",
      "7529\n",
      "7530\n",
      "7531\n",
      "7532\n",
      "7533\n",
      "7534\n",
      "7535\n",
      "7536\n",
      "7537\n",
      "7538\n",
      "7539\n",
      "7540\n",
      "7541\n",
      "7542\n",
      "7543\n",
      "7544\n",
      "7545\n",
      "7546\n",
      "7547\n",
      "7548\n",
      "7549\n",
      "7550\n",
      "7551\n",
      "7552\n",
      "7553\n",
      "7554\n",
      "7555\n",
      "7556\n",
      "7557\n",
      "7558\n",
      "7559\n",
      "7560\n",
      "7561\n",
      "7562\n",
      "7563\n",
      "7564\n",
      "7565\n",
      "7566\n",
      "7567\n",
      "7568\n",
      "7569\n",
      "7570\n",
      "7571\n",
      "7572\n",
      "7573\n",
      "7574\n",
      "7575\n",
      "7576\n",
      "7577\n",
      "7578\n",
      "7579\n",
      "7580\n",
      "7581\n",
      "7582\n",
      "7583\n",
      "7584\n",
      "7585\n",
      "7586\n",
      "7587\n",
      "7588\n",
      "7589\n",
      "7590\n",
      "7591\n",
      "7592\n",
      "7593\n",
      "7594\n",
      "7595\n",
      "7596\n",
      "7597\n",
      "7598\n",
      "7599\n",
      "7600\n",
      "7601\n",
      "7602\n",
      "7603\n",
      "7604\n",
      "7605\n",
      "7606\n",
      "7607\n",
      "7608\n",
      "7609\n",
      "7610\n",
      "7611\n",
      "7612\n",
      "7613\n",
      "7614\n",
      "7615\n",
      "7616\n",
      "7617\n",
      "7618\n",
      "7619\n",
      "7620\n",
      "7621\n",
      "7622\n",
      "7623\n",
      "7624\n",
      "7625\n",
      "7626\n",
      "7627\n",
      "7628\n",
      "7629\n",
      "7630\n",
      "7631\n",
      "7632\n",
      "7633\n",
      "7634\n",
      "7635\n",
      "7636\n",
      "7637\n",
      "7638\n",
      "7639\n",
      "7640\n",
      "7641\n",
      "7642\n",
      "7643\n",
      "7644\n",
      "7645\n",
      "7646\n",
      "7647\n",
      "7648\n",
      "7649\n",
      "7650\n",
      "7651\n",
      "7652\n",
      "7653\n",
      "7654\n",
      "7655\n",
      "7656\n",
      "7657\n",
      "7658\n",
      "7659\n",
      "7660\n",
      "7661\n",
      "7662\n",
      "7663\n",
      "7664\n",
      "7665\n",
      "7666\n",
      "7667\n",
      "7668\n",
      "7669\n",
      "7670\n",
      "7671\n",
      "7672\n",
      "7673\n",
      "7674\n",
      "7675\n",
      "7676\n",
      "7677\n",
      "7678\n",
      "7679\n",
      "7680\n",
      "7681\n",
      "7682\n",
      "7683\n",
      "7684\n",
      "7685\n",
      "7686\n",
      "7687\n",
      "7688\n",
      "7689\n",
      "7690\n",
      "7691\n",
      "7692\n",
      "7693\n",
      "7694\n",
      "7695\n",
      "7696\n",
      "7697\n",
      "7698\n",
      "7699\n",
      "7700\n",
      "7701\n",
      "7702\n",
      "7703\n",
      "7704\n",
      "7705\n",
      "7706\n",
      "7707\n",
      "7708\n",
      "7709\n",
      "7710\n",
      "7711\n",
      "7712\n",
      "7713\n",
      "7714\n",
      "7715\n",
      "7716\n",
      "7717\n",
      "7718\n",
      "7719\n",
      "7720\n",
      "7721\n",
      "7722\n",
      "7723\n",
      "7724\n",
      "7725\n",
      "7726\n",
      "7727\n",
      "7728\n",
      "7729\n",
      "7730\n",
      "7731\n",
      "7732\n",
      "7733\n",
      "7734\n",
      "7735\n",
      "7736\n",
      "7737\n",
      "7738\n",
      "7739\n",
      "7740\n",
      "7741\n",
      "7742\n",
      "7743\n",
      "7744\n",
      "7745\n",
      "7746\n",
      "7747\n",
      "7748\n",
      "7749\n",
      "7750\n",
      "7751\n",
      "7752\n",
      "7753\n",
      "7754\n",
      "7755\n",
      "7756\n",
      "7757\n",
      "7758\n",
      "7759\n",
      "7760\n",
      "7761\n",
      "7762\n",
      "7763\n",
      "7764\n",
      "7765\n",
      "7766\n",
      "7767\n",
      "7768\n",
      "7769\n",
      "7770\n",
      "7771\n",
      "7772\n",
      "7773\n",
      "7774\n",
      "7775\n",
      "7776\n",
      "7777\n",
      "7778\n",
      "7779\n",
      "7780\n",
      "7781\n",
      "7782\n",
      "7783\n",
      "7784\n",
      "7785\n",
      "7786\n",
      "7787\n",
      "7788\n",
      "7789\n",
      "7790\n",
      "7791\n",
      "7792\n",
      "7793\n",
      "7794\n",
      "7795\n",
      "7796\n",
      "7797\n",
      "7798\n",
      "7799\n",
      "7800\n",
      "7801\n",
      "7802\n",
      "7803\n",
      "7804\n",
      "7805\n",
      "7806\n",
      "7807\n",
      "7808\n",
      "7809\n",
      "7810\n",
      "7811\n",
      "7812\n",
      "7813\n",
      "7814\n",
      "7815\n",
      "7816\n",
      "7817\n",
      "7818\n",
      "7819\n",
      "7820\n",
      "7821\n",
      "7822\n",
      "7823\n",
      "7824\n",
      "7825\n",
      "7826\n",
      "7827\n",
      "7828\n",
      "7829\n",
      "7830\n",
      "7831\n",
      "7832\n",
      "7833\n",
      "7834\n",
      "7835\n",
      "7836\n",
      "7837\n",
      "7838\n",
      "7839\n",
      "7840\n",
      "7841\n",
      "7842\n",
      "7843\n",
      "7844\n",
      "7845\n",
      "7846\n",
      "7847\n",
      "7848\n",
      "7849\n",
      "7850\n",
      "7851\n",
      "7852\n",
      "7853\n",
      "7854\n",
      "7855\n",
      "7856\n",
      "7857\n",
      "7858\n",
      "7859\n",
      "7860\n",
      "7861\n",
      "7862\n",
      "7863\n",
      "7864\n",
      "7865\n",
      "7866\n",
      "7867\n",
      "7868\n",
      "7869\n",
      "7870\n",
      "7871\n",
      "7872\n",
      "7873\n",
      "7874\n",
      "7875\n",
      "7876\n",
      "7877\n",
      "7878\n",
      "7879\n",
      "7880\n",
      "7881\n",
      "7882\n",
      "7883\n",
      "7884\n",
      "7885\n",
      "7886\n",
      "7887\n",
      "7888\n",
      "7889\n",
      "7890\n",
      "7891\n",
      "7892\n",
      "7893\n",
      "7894\n",
      "7895\n",
      "7896\n",
      "7897\n",
      "7898\n",
      "7899\n",
      "7900\n",
      "7901\n",
      "7902\n",
      "7903\n",
      "7904\n",
      "7905\n",
      "7906\n",
      "7907\n",
      "7908\n",
      "7909\n",
      "7910\n",
      "7911\n",
      "7912\n",
      "7913\n",
      "7914\n",
      "7915\n",
      "7916\n",
      "7917\n",
      "7918\n",
      "7919\n",
      "7920\n",
      "7921\n",
      "7922\n",
      "7923\n",
      "7924\n",
      "7925\n",
      "7926\n",
      "7927\n",
      "7928\n",
      "7929\n",
      "7930\n",
      "7931\n",
      "7932\n",
      "7933\n",
      "7934\n",
      "7935\n",
      "7936\n",
      "7937\n",
      "7938\n",
      "7939\n",
      "7940\n",
      "7941\n",
      "7942\n",
      "7943\n",
      "7944\n",
      "7945\n",
      "7946\n",
      "7947\n",
      "7948\n",
      "7949\n",
      "7950\n",
      "7951\n",
      "7952\n",
      "7953\n",
      "7954\n",
      "7955\n",
      "7956\n",
      "7957\n",
      "7958\n",
      "7959\n",
      "7960\n",
      "7961\n",
      "7962\n",
      "7963\n",
      "7964\n",
      "7965\n",
      "7966\n",
      "7967\n",
      "7968\n",
      "7969\n",
      "7970\n",
      "7971\n",
      "7972\n",
      "7973\n",
      "7974\n",
      "7975\n",
      "7976\n",
      "7977\n",
      "7978\n",
      "7979\n",
      "7980\n",
      "7981\n",
      "7982\n",
      "7983\n",
      "7984\n",
      "7985\n",
      "7986\n",
      "7987\n",
      "7988\n",
      "7989\n",
      "7990\n",
      "7991\n",
      "7992\n",
      "7993\n",
      "7994\n",
      "7995\n",
      "7996\n",
      "7997\n",
      "7998\n",
      "7999\n",
      "8000\n",
      "8001\n",
      "8002\n",
      "8003\n",
      "8004\n",
      "8005\n",
      "8006\n",
      "8007\n",
      "8008\n",
      "8009\n",
      "8010\n",
      "8011\n",
      "8012\n",
      "8013\n",
      "8014\n",
      "8015\n",
      "8016\n",
      "8017\n",
      "8018\n",
      "8019\n",
      "8020\n",
      "8021\n",
      "8022\n",
      "8023\n",
      "8024\n",
      "8025\n",
      "8026\n",
      "8027\n",
      "8028\n",
      "8029\n",
      "8030\n",
      "8031\n",
      "8032\n",
      "8033\n",
      "8034\n",
      "8035\n",
      "8036\n",
      "8037\n",
      "8038\n",
      "8039\n",
      "8040\n",
      "8041\n",
      "8042\n",
      "8043\n",
      "8044\n",
      "8045\n",
      "8046\n",
      "8047\n",
      "8048\n",
      "8049\n",
      "8050\n",
      "8051\n",
      "8052\n",
      "8053\n",
      "8054\n",
      "8055\n",
      "8056\n",
      "8057\n",
      "8058\n",
      "8059\n",
      "8060\n",
      "8061\n",
      "8062\n",
      "8063\n",
      "8064\n",
      "8065\n",
      "8066\n",
      "8067\n",
      "8068\n",
      "8069\n",
      "8070\n",
      "8071\n",
      "8072\n",
      "8073\n",
      "8074\n",
      "8075\n",
      "8076\n",
      "8077\n",
      "8078\n",
      "8079\n",
      "8080\n",
      "8081\n",
      "8082\n",
      "8083\n",
      "8084\n",
      "8085\n",
      "8086\n",
      "8087\n",
      "8088\n",
      "8089\n",
      "8090\n",
      "8091\n",
      "8092\n",
      "8093\n",
      "8094\n",
      "8095\n",
      "8096\n",
      "8097\n",
      "8098\n",
      "8099\n",
      "8100\n",
      "8101\n",
      "8102\n",
      "8103\n",
      "8104\n",
      "8105\n",
      "8106\n",
      "8107\n",
      "8108\n",
      "8109\n",
      "8110\n",
      "8111\n",
      "8112\n",
      "8113\n",
      "8114\n",
      "8115\n",
      "8116\n",
      "8117\n",
      "8118\n",
      "8119\n",
      "8120\n",
      "8121\n",
      "8122\n",
      "8123\n",
      "8124\n",
      "8125\n",
      "8126\n",
      "8127\n",
      "8128\n",
      "8129\n",
      "8130\n",
      "8131\n",
      "8132\n",
      "8133\n",
      "8134\n",
      "8135\n",
      "8136\n",
      "8137\n",
      "8138\n",
      "8139\n",
      "8140\n",
      "8141\n",
      "8142\n",
      "8143\n",
      "8144\n",
      "8145\n",
      "8146\n",
      "8147\n",
      "8148\n",
      "8149\n",
      "8150\n",
      "8151\n",
      "8152\n",
      "8153\n",
      "8154\n",
      "8155\n",
      "8156\n",
      "8157\n",
      "8158\n",
      "8159\n",
      "8160\n",
      "8161\n",
      "8162\n",
      "8163\n",
      "8164\n",
      "8165\n",
      "8166\n",
      "8167\n",
      "8168\n",
      "8169\n",
      "8170\n",
      "8171\n",
      "8172\n",
      "8173\n",
      "8174\n",
      "8175\n",
      "8176\n",
      "8177\n",
      "8178\n",
      "8179\n",
      "8180\n",
      "8181\n",
      "8182\n",
      "8183\n",
      "8184\n",
      "8185\n",
      "8186\n",
      "8187\n",
      "8188\n",
      "8189\n",
      "8190\n",
      "8191\n",
      "8192\n",
      "8193\n",
      "8194\n",
      "8195\n",
      "8196\n",
      "8197\n",
      "8198\n",
      "8199\n",
      "8200\n",
      "8201\n",
      "8202\n",
      "8203\n",
      "8204\n",
      "8205\n",
      "8206\n",
      "8207\n",
      "8208\n",
      "8209\n",
      "8210\n",
      "8211\n",
      "8212\n",
      "8213\n",
      "8214\n",
      "8215\n",
      "8216\n",
      "8217\n",
      "8218\n",
      "8219\n",
      "8220\n",
      "8221\n",
      "8222\n",
      "8223\n",
      "8224\n",
      "8225\n",
      "8226\n",
      "8227\n",
      "8228\n",
      "8229\n",
      "8230\n",
      "8231\n",
      "8232\n",
      "8233\n",
      "8234\n",
      "8235\n",
      "8236\n",
      "8237\n",
      "8238\n",
      "8239\n",
      "8240\n",
      "8241\n",
      "8242\n",
      "8243\n",
      "8244\n",
      "8245\n",
      "8246\n",
      "8247\n",
      "8248\n",
      "8249\n",
      "8250\n",
      "8251\n",
      "8252\n",
      "8253\n",
      "8254\n",
      "8255\n",
      "8256\n",
      "8257\n",
      "8258\n",
      "8259\n",
      "8260\n",
      "8261\n",
      "8262\n",
      "8263\n",
      "8264\n",
      "8265\n",
      "8266\n",
      "8267\n",
      "8268\n",
      "8269\n",
      "8270\n",
      "8271\n",
      "8272\n",
      "8273\n",
      "8274\n",
      "8275\n",
      "8276\n",
      "8277\n",
      "8278\n",
      "8279\n",
      "8280\n",
      "8281\n",
      "8282\n",
      "8283\n",
      "8284\n",
      "8285\n",
      "8286\n",
      "8287\n",
      "8288\n",
      "8289\n",
      "8290\n",
      "8291\n",
      "8292\n",
      "8293\n",
      "8294\n",
      "8295\n",
      "8296\n",
      "8297\n",
      "8298\n",
      "8299\n",
      "8300\n",
      "8301\n",
      "8302\n",
      "8303\n",
      "8304\n",
      "8305\n",
      "8306\n",
      "8307\n",
      "8308\n",
      "8309\n",
      "8310\n",
      "8311\n",
      "8312\n",
      "8313\n",
      "8314\n",
      "8315\n",
      "8316\n",
      "8317\n",
      "8318\n",
      "8319\n",
      "8320\n",
      "8321\n",
      "8322\n",
      "8323\n",
      "8324\n",
      "8325\n",
      "8326\n",
      "8327\n",
      "8328\n",
      "8329\n",
      "8330\n",
      "8331\n",
      "8332\n",
      "8333\n",
      "8334\n",
      "8335\n",
      "8336\n",
      "8337\n",
      "8338\n",
      "8339\n",
      "8340\n",
      "8341\n",
      "8342\n",
      "8343\n",
      "8344\n",
      "8345\n",
      "8346\n",
      "8347\n",
      "8348\n",
      "8349\n",
      "8350\n",
      "8351\n",
      "8352\n",
      "8353\n",
      "8354\n",
      "8355\n",
      "8356\n",
      "8357\n",
      "8358\n",
      "8359\n",
      "8360\n",
      "8361\n",
      "8362\n",
      "8363\n",
      "8364\n",
      "8365\n",
      "8366\n",
      "8367\n",
      "8368\n",
      "8369\n",
      "8370\n",
      "8371\n",
      "8372\n",
      "8373\n",
      "8374\n",
      "8375\n",
      "8376\n",
      "8377\n",
      "8378\n",
      "8379\n",
      "8380\n",
      "8381\n",
      "8382\n",
      "8383\n",
      "8384\n",
      "8385\n",
      "8386\n",
      "8387\n",
      "8388\n",
      "8389\n",
      "8390\n",
      "8391\n",
      "8392\n",
      "8393\n",
      "8394\n",
      "8395\n",
      "8396\n",
      "8397\n",
      "8398\n",
      "8399\n",
      "8400\n",
      "8401\n",
      "8402\n",
      "8403\n",
      "8404\n",
      "8405\n",
      "8406\n",
      "8407\n",
      "8408\n",
      "8409\n",
      "8410\n",
      "8411\n",
      "8412\n",
      "8413\n",
      "8414\n",
      "8415\n",
      "8416\n",
      "8417\n",
      "8418\n",
      "8419\n",
      "8420\n",
      "8421\n",
      "8422\n",
      "8423\n",
      "8424\n",
      "8425\n",
      "8426\n",
      "8427\n",
      "8428\n",
      "8429\n",
      "8430\n",
      "8431\n",
      "8432\n",
      "8433\n",
      "8434\n",
      "8435\n",
      "8436\n",
      "8437\n",
      "8438\n",
      "8439\n",
      "8440\n",
      "8441\n",
      "8442\n",
      "8443\n",
      "8444\n",
      "8445\n",
      "8446\n",
      "8447\n",
      "8448\n",
      "8449\n",
      "8450\n",
      "8451\n",
      "8452\n",
      "8453\n",
      "8454\n",
      "8455\n",
      "8456\n",
      "8457\n",
      "8458\n",
      "8459\n",
      "8460\n",
      "8461\n",
      "8462\n",
      "8463\n",
      "8464\n",
      "8465\n",
      "8466\n",
      "8467\n",
      "8468\n",
      "8469\n",
      "8470\n",
      "8471\n",
      "8472\n",
      "8473\n",
      "8474\n",
      "8475\n",
      "8476\n",
      "8477\n",
      "8478\n",
      "8479\n",
      "8480\n",
      "8481\n",
      "8482\n",
      "8483\n",
      "8484\n",
      "8485\n",
      "8486\n",
      "8487\n",
      "8488\n",
      "8489\n",
      "8490\n",
      "8491\n",
      "8492\n",
      "8493\n",
      "8494\n",
      "8495\n",
      "8496\n",
      "8497\n",
      "8498\n",
      "8499\n",
      "8500\n",
      "8501\n",
      "8502\n",
      "8503\n",
      "8504\n",
      "8505\n",
      "8506\n",
      "8507\n",
      "8508\n",
      "8509\n",
      "8510\n",
      "8511\n",
      "8512\n",
      "8513\n",
      "8514\n",
      "8515\n",
      "8516\n",
      "8517\n",
      "8518\n",
      "8519\n",
      "8520\n",
      "8521\n",
      "8522\n",
      "8523\n",
      "8524\n",
      "8525\n",
      "8526\n",
      "8527\n",
      "8528\n",
      "8529\n",
      "8530\n",
      "8531\n",
      "8532\n",
      "8533\n",
      "8534\n",
      "8535\n",
      "8536\n",
      "8537\n",
      "8538\n",
      "8539\n",
      "8540\n",
      "8541\n",
      "8542\n",
      "8543\n",
      "8544\n",
      "8545\n",
      "8546\n",
      "8547\n",
      "8548\n",
      "8549\n",
      "8550\n",
      "8551\n",
      "8552\n",
      "8553\n",
      "8554\n",
      "8555\n",
      "8556\n",
      "8557\n",
      "8558\n",
      "8559\n",
      "8560\n",
      "8561\n",
      "8562\n",
      "8563\n",
      "8564\n",
      "8565\n",
      "8566\n",
      "8567\n",
      "8568\n",
      "8569\n",
      "8570\n",
      "8571\n",
      "8572\n",
      "8573\n",
      "8574\n",
      "8575\n",
      "8576\n",
      "8577\n",
      "8578\n",
      "8579\n",
      "8580\n",
      "8581\n",
      "8582\n",
      "8583\n",
      "8584\n",
      "8585\n",
      "8586\n",
      "8587\n",
      "8588\n",
      "8589\n",
      "8590\n",
      "8591\n",
      "8592\n",
      "8593\n",
      "8594\n",
      "8595\n",
      "8596\n",
      "8597\n",
      "8598\n",
      "8599\n",
      "8600\n",
      "8601\n",
      "8602\n",
      "8603\n",
      "8604\n",
      "8605\n",
      "8606\n",
      "8607\n",
      "8608\n",
      "8609\n",
      "8610\n",
      "8611\n",
      "8612\n",
      "8613\n",
      "8614\n",
      "8615\n",
      "8616\n",
      "8617\n",
      "8618\n",
      "8619\n",
      "8620\n",
      "8621\n",
      "8622\n",
      "8623\n",
      "8624\n",
      "8625\n",
      "8626\n",
      "8627\n",
      "8628\n",
      "8629\n",
      "8630\n",
      "8631\n",
      "8632\n",
      "8633\n",
      "8634\n",
      "8635\n",
      "8636\n",
      "8637\n",
      "8638\n",
      "8639\n",
      "8640\n",
      "8641\n",
      "8642\n",
      "8643\n",
      "8644\n",
      "8645\n",
      "8646\n",
      "8647\n",
      "8648\n",
      "8649\n",
      "8650\n",
      "8651\n",
      "8652\n",
      "8653\n",
      "8654\n",
      "8655\n",
      "8656\n",
      "8657\n",
      "8658\n",
      "8659\n",
      "8660\n",
      "8661\n",
      "8662\n",
      "8663\n",
      "8664\n",
      "8665\n",
      "8666\n",
      "8667\n",
      "8668\n",
      "8669\n",
      "8670\n",
      "8671\n",
      "8672\n",
      "8673\n",
      "8674\n",
      "8675\n",
      "8676\n",
      "8677\n",
      "8678\n",
      "8679\n",
      "8680\n",
      "8681\n",
      "8682\n",
      "8683\n",
      "8684\n",
      "8685\n",
      "8686\n",
      "8687\n",
      "8688\n",
      "8689\n",
      "8690\n",
      "8691\n",
      "8692\n",
      "8693\n",
      "8694\n",
      "8695\n",
      "8696\n",
      "8697\n",
      "8698\n",
      "8699\n",
      "8700\n",
      "8701\n",
      "8702\n",
      "8703\n",
      "8704\n",
      "8705\n",
      "8706\n",
      "8707\n",
      "8708\n",
      "8709\n",
      "8710\n",
      "8711\n",
      "8712\n",
      "8713\n",
      "8714\n",
      "8715\n",
      "8716\n",
      "8717\n",
      "8718\n",
      "8719\n",
      "8720\n",
      "8721\n",
      "8722\n",
      "8723\n",
      "8724\n",
      "8725\n",
      "8726\n",
      "8727\n",
      "8728\n",
      "8729\n",
      "8730\n",
      "8731\n",
      "8732\n",
      "8733\n",
      "8734\n",
      "8735\n",
      "8736\n",
      "8737\n",
      "8738\n",
      "8739\n",
      "8740\n",
      "8741\n",
      "8742\n",
      "8743\n",
      "8744\n",
      "8745\n",
      "8746\n",
      "8747\n",
      "8748\n",
      "8749\n",
      "8750\n",
      "8751\n",
      "8752\n",
      "8753\n",
      "8754\n",
      "8755\n",
      "8756\n",
      "8757\n",
      "8758\n",
      "8759\n",
      "8760\n",
      "8761\n",
      "8762\n",
      "8763\n",
      "8764\n",
      "8765\n",
      "8766\n",
      "8767\n",
      "8768\n",
      "8769\n",
      "8770\n",
      "8771\n",
      "8772\n",
      "8773\n",
      "8774\n",
      "8775\n",
      "8776\n",
      "8777\n",
      "8778\n",
      "8779\n",
      "8780\n",
      "8781\n",
      "8782\n",
      "8783\n",
      "8784\n",
      "8785\n",
      "8786\n",
      "8787\n",
      "8788\n",
      "8789\n",
      "8790\n",
      "8791\n",
      "8792\n",
      "8793\n",
      "8794\n",
      "8795\n",
      "8796\n",
      "8797\n",
      "8798\n",
      "8799\n",
      "8800\n",
      "8801\n",
      "8802\n",
      "8803\n",
      "8804\n",
      "8805\n",
      "8806\n",
      "8807\n",
      "8808\n",
      "8809\n",
      "8810\n",
      "8811\n",
      "8812\n",
      "8813\n",
      "8814\n",
      "8815\n",
      "8816\n",
      "8817\n",
      "8818\n",
      "8819\n",
      "8820\n",
      "8821\n",
      "8822\n",
      "8823\n",
      "8824\n",
      "8825\n",
      "8826\n",
      "8827\n",
      "8828\n",
      "8829\n",
      "8830\n",
      "8831\n",
      "8832\n",
      "8833\n",
      "8834\n",
      "8835\n",
      "8836\n",
      "8837\n",
      "8838\n",
      "8839\n",
      "8840\n",
      "8841\n",
      "8842\n",
      "8843\n",
      "8844\n",
      "8845\n",
      "8846\n",
      "8847\n",
      "8848\n",
      "8849\n",
      "8850\n",
      "8851\n",
      "8852\n",
      "8853\n",
      "8854\n",
      "8855\n",
      "8856\n",
      "8857\n",
      "8858\n",
      "8859\n",
      "8860\n",
      "8861\n",
      "8862\n",
      "8863\n",
      "8864\n",
      "8865\n",
      "8866\n",
      "8867\n",
      "8868\n",
      "8869\n",
      "8870\n",
      "8871\n",
      "8872\n",
      "8873\n",
      "8874\n",
      "8875\n",
      "8876\n",
      "8877\n",
      "8878\n",
      "8879\n",
      "8880\n",
      "8881\n",
      "8882\n",
      "8883\n",
      "8884\n",
      "8885\n",
      "8886\n",
      "8887\n",
      "8888\n",
      "8889\n",
      "8890\n",
      "8891\n",
      "8892\n",
      "8893\n",
      "8894\n",
      "8895\n",
      "8896\n",
      "8897\n",
      "8898\n",
      "8899\n",
      "8900\n",
      "8901\n",
      "8902\n",
      "8903\n",
      "8904\n",
      "8905\n",
      "8906\n",
      "8907\n",
      "8908\n",
      "8909\n",
      "8910\n",
      "8911\n",
      "8912\n",
      "8913\n",
      "8914\n",
      "8915\n",
      "8916\n",
      "8917\n",
      "8918\n",
      "8919\n",
      "8920\n",
      "8921\n",
      "8922\n",
      "8923\n",
      "8924\n",
      "8925\n",
      "8926\n",
      "8927\n",
      "8928\n",
      "8929\n",
      "8930\n",
      "8931\n",
      "8932\n",
      "8933\n",
      "8934\n",
      "8935\n",
      "8936\n",
      "8937\n",
      "8938\n",
      "8939\n",
      "8940\n",
      "8941\n",
      "8942\n",
      "8943\n",
      "8944\n",
      "8945\n",
      "8946\n",
      "8947\n",
      "8948\n",
      "8949\n",
      "8950\n",
      "8951\n",
      "8952\n",
      "8953\n",
      "8954\n",
      "8955\n",
      "8956\n",
      "8957\n",
      "8958\n",
      "8959\n",
      "8960\n",
      "8961\n",
      "8962\n",
      "8963\n",
      "8964\n",
      "8965\n",
      "8966\n",
      "8967\n",
      "8968\n",
      "8969\n",
      "8970\n",
      "8971\n",
      "8972\n",
      "8973\n",
      "8974\n",
      "8975\n",
      "8976\n",
      "8977\n",
      "8978\n",
      "8979\n",
      "8980\n",
      "8981\n",
      "8982\n",
      "8983\n",
      "8984\n",
      "8985\n",
      "8986\n",
      "8987\n",
      "8988\n",
      "8989\n",
      "8990\n",
      "8991\n",
      "8992\n",
      "8993\n",
      "8994\n",
      "8995\n",
      "8996\n",
      "8997\n",
      "8998\n",
      "8999\n",
      "9000\n",
      "9001\n",
      "9002\n",
      "9003\n",
      "9004\n",
      "9005\n",
      "9006\n",
      "9007\n",
      "9008\n",
      "9009\n",
      "9010\n",
      "9011\n",
      "9012\n",
      "9013\n",
      "9014\n",
      "9015\n",
      "9016\n",
      "9017\n",
      "9018\n",
      "9019\n",
      "9020\n",
      "9021\n",
      "9022\n",
      "9023\n",
      "9024\n",
      "9025\n",
      "9026\n",
      "9027\n",
      "9028\n",
      "9029\n",
      "9030\n",
      "9031\n",
      "9032\n",
      "9033\n",
      "9034\n",
      "9035\n",
      "9036\n",
      "9037\n",
      "9038\n",
      "9039\n",
      "9040\n",
      "9041\n",
      "9042\n",
      "9043\n",
      "9044\n",
      "9045\n",
      "9046\n",
      "9047\n",
      "9048\n",
      "9049\n",
      "9050\n",
      "9051\n",
      "9052\n",
      "9053\n",
      "9054\n",
      "9055\n",
      "9056\n",
      "9057\n",
      "9058\n",
      "9059\n",
      "9060\n",
      "9061\n",
      "9062\n",
      "9063\n",
      "9064\n",
      "9065\n",
      "9066\n",
      "9067\n",
      "9068\n",
      "9069\n",
      "9070\n",
      "9071\n",
      "9072\n",
      "9073\n",
      "9074\n",
      "9075\n",
      "9076\n",
      "9077\n",
      "9078\n",
      "9079\n",
      "9080\n",
      "9081\n",
      "9082\n",
      "9083\n",
      "9084\n",
      "9085\n",
      "9086\n",
      "9087\n",
      "9088\n",
      "9089\n",
      "9090\n",
      "9091\n",
      "9092\n",
      "9093\n",
      "9094\n",
      "9095\n",
      "9096\n",
      "9097\n",
      "9098\n",
      "9099\n",
      "9100\n",
      "9101\n",
      "9102\n",
      "9103\n",
      "9104\n",
      "9105\n",
      "9106\n",
      "9107\n",
      "9108\n",
      "9109\n",
      "9110\n",
      "9111\n",
      "9112\n",
      "9113\n",
      "9114\n",
      "9115\n",
      "9116\n",
      "9117\n",
      "9118\n",
      "9119\n",
      "9120\n",
      "9121\n",
      "9122\n",
      "9123\n",
      "9124\n",
      "9125\n",
      "9126\n",
      "9127\n",
      "9128\n",
      "9129\n",
      "9130\n",
      "9131\n",
      "9132\n",
      "9133\n",
      "9134\n",
      "9135\n",
      "9136\n",
      "9137\n",
      "9138\n",
      "9139\n",
      "9140\n",
      "9141\n",
      "9142\n",
      "9143\n",
      "9144\n",
      "9145\n",
      "9146\n",
      "9147\n",
      "9148\n",
      "9149\n",
      "9150\n",
      "9151\n",
      "9152\n",
      "9153\n",
      "9154\n",
      "9155\n",
      "9156\n",
      "9157\n",
      "9158\n",
      "9159\n",
      "9160\n",
      "9161\n",
      "9162\n",
      "9163\n",
      "9164\n",
      "9165\n",
      "9166\n",
      "9167\n",
      "9168\n",
      "9169\n",
      "9170\n",
      "9171\n",
      "9172\n",
      "9173\n",
      "9174\n",
      "9175\n",
      "9176\n",
      "9177\n",
      "9178\n",
      "9179\n",
      "9180\n",
      "9181\n",
      "9182\n",
      "9183\n",
      "9184\n",
      "9185\n",
      "9186\n",
      "9187\n",
      "9188\n",
      "9189\n",
      "9190\n",
      "9191\n",
      "9192\n",
      "9193\n",
      "9194\n",
      "9195\n",
      "9196\n",
      "9197\n",
      "9198\n",
      "9199\n",
      "9200\n",
      "9201\n",
      "9202\n",
      "9203\n",
      "9204\n",
      "9205\n",
      "9206\n",
      "9207\n",
      "9208\n",
      "9209\n",
      "9210\n",
      "9211\n",
      "9212\n",
      "9213\n",
      "9214\n",
      "9215\n",
      "9216\n",
      "9217\n",
      "9218\n",
      "9219\n",
      "9220\n",
      "9221\n",
      "9222\n",
      "9223\n",
      "9224\n",
      "9225\n",
      "9226\n",
      "9227\n",
      "9228\n",
      "9229\n",
      "9230\n",
      "9231\n",
      "9232\n",
      "9233\n",
      "9234\n",
      "9235\n",
      "9236\n",
      "9237\n",
      "9238\n",
      "9239\n",
      "9240\n",
      "9241\n",
      "9242\n",
      "9243\n",
      "9244\n",
      "9245\n",
      "9246\n",
      "9247\n",
      "9248\n",
      "9249\n",
      "9250\n",
      "9251\n",
      "9252\n",
      "9253\n",
      "9254\n",
      "9255\n",
      "9256\n",
      "9257\n",
      "9258\n",
      "9259\n",
      "9260\n",
      "9261\n",
      "9262\n",
      "9263\n",
      "9264\n",
      "9265\n",
      "9266\n",
      "9267\n",
      "9268\n",
      "9269\n",
      "9270\n",
      "9271\n",
      "9272\n",
      "9273\n",
      "9274\n",
      "9275\n",
      "9276\n",
      "9277\n",
      "9278\n",
      "9279\n",
      "9280\n",
      "9281\n",
      "9282\n",
      "9283\n",
      "9284\n",
      "9285\n",
      "9286\n",
      "9287\n",
      "9288\n",
      "9289\n",
      "9290\n",
      "9291\n",
      "9292\n",
      "9293\n",
      "9294\n",
      "9295\n",
      "9296\n",
      "9297\n",
      "9298\n",
      "9299\n",
      "9300\n",
      "9301\n",
      "9302\n",
      "9303\n",
      "9304\n",
      "9305\n",
      "9306\n",
      "9307\n",
      "9308\n",
      "9309\n",
      "9310\n",
      "9311\n",
      "9312\n",
      "9313\n",
      "9314\n",
      "9315\n",
      "9316\n",
      "9317\n",
      "9318\n",
      "9319\n",
      "9320\n",
      "9321\n",
      "9322\n",
      "9323\n",
      "9324\n",
      "9325\n",
      "9326\n",
      "9327\n",
      "9328\n",
      "9329\n",
      "9330\n",
      "9331\n",
      "9332\n",
      "9333\n",
      "9334\n",
      "9335\n",
      "9336\n",
      "9337\n",
      "9338\n",
      "9339\n",
      "9340\n",
      "9341\n",
      "9342\n",
      "9343\n",
      "9344\n",
      "9345\n",
      "9346\n",
      "9347\n",
      "9348\n",
      "9349\n",
      "9350\n",
      "9351\n",
      "9352\n",
      "9353\n",
      "9354\n",
      "9355\n",
      "9356\n",
      "9357\n",
      "9358\n",
      "9359\n",
      "9360\n",
      "9361\n",
      "9362\n",
      "9363\n",
      "9364\n",
      "9365\n",
      "9366\n",
      "9367\n",
      "9368\n",
      "9369\n",
      "9370\n",
      "9371\n",
      "9372\n",
      "9373\n",
      "9374\n",
      "9375\n",
      "9376\n",
      "9377\n",
      "9378\n",
      "9379\n",
      "9380\n",
      "9381\n",
      "9382\n",
      "9383\n",
      "9384\n",
      "9385\n",
      "9386\n",
      "9387\n",
      "9388\n",
      "9389\n",
      "9390\n",
      "9391\n",
      "9392\n",
      "9393\n",
      "9394\n",
      "9395\n",
      "9396\n",
      "9397\n",
      "9398\n",
      "9399\n",
      "9400\n",
      "9401\n",
      "9402\n",
      "9403\n",
      "9404\n",
      "9405\n",
      "9406\n",
      "9407\n",
      "9408\n",
      "9409\n",
      "9410\n",
      "9411\n",
      "9412\n",
      "9413\n",
      "9414\n",
      "9415\n",
      "9416\n",
      "9417\n",
      "9418\n",
      "9419\n",
      "9420\n",
      "9421\n",
      "9422\n",
      "9423\n",
      "9424\n",
      "9425\n",
      "9426\n",
      "9427\n",
      "9428\n",
      "9429\n",
      "9430\n",
      "9431\n",
      "9432\n",
      "9433\n",
      "9434\n",
      "9435\n",
      "9436\n",
      "9437\n",
      "9438\n",
      "9439\n",
      "9440\n",
      "9441\n",
      "9442\n",
      "9443\n",
      "9444\n",
      "9445\n",
      "9446\n",
      "9447\n",
      "9448\n",
      "9449\n",
      "9450\n",
      "9451\n",
      "9452\n",
      "9453\n",
      "9454\n",
      "9455\n",
      "9456\n",
      "9457\n",
      "9458\n",
      "9459\n",
      "9460\n",
      "9461\n",
      "9462\n",
      "9463\n",
      "9464\n",
      "9465\n",
      "9466\n",
      "9467\n",
      "9468\n",
      "9469\n",
      "9470\n",
      "9471\n",
      "9472\n",
      "9473\n",
      "9474\n",
      "9475\n",
      "9476\n",
      "9477\n",
      "9478\n",
      "9479\n",
      "9480\n",
      "9481\n",
      "9482\n",
      "9483\n",
      "9484\n",
      "9485\n",
      "9486\n",
      "9487\n",
      "9488\n",
      "9489\n",
      "9490\n",
      "9491\n",
      "9492\n",
      "9493\n",
      "9494\n",
      "9495\n",
      "9496\n",
      "9497\n",
      "9498\n",
      "9499\n",
      "9500\n",
      "9501\n",
      "9502\n",
      "9503\n",
      "9504\n",
      "9505\n",
      "9506\n",
      "9507\n",
      "9508\n",
      "9509\n",
      "9510\n",
      "9511\n",
      "9512\n",
      "9513\n",
      "9514\n",
      "9515\n",
      "9516\n",
      "9517\n",
      "9518\n",
      "9519\n",
      "9520\n",
      "9521\n",
      "9522\n",
      "9523\n",
      "9524\n",
      "9525\n",
      "9526\n",
      "9527\n",
      "9528\n",
      "9529\n",
      "9530\n",
      "9531\n",
      "9532\n",
      "9533\n",
      "9534\n",
      "9535\n",
      "9536\n",
      "9537\n",
      "9538\n",
      "9539\n",
      "9540\n",
      "9541\n",
      "9542\n",
      "9543\n",
      "9544\n",
      "9545\n",
      "9546\n",
      "9547\n",
      "9548\n",
      "9549\n",
      "9550\n",
      "9551\n",
      "9552\n",
      "9553\n",
      "9554\n",
      "9555\n",
      "9556\n",
      "9557\n",
      "9558\n",
      "9559\n",
      "9560\n",
      "9561\n",
      "9562\n",
      "9563\n",
      "9564\n",
      "9565\n",
      "9566\n",
      "9567\n",
      "9568\n",
      "9569\n",
      "9570\n",
      "9571\n",
      "9572\n",
      "9573\n",
      "9574\n",
      "9575\n",
      "9576\n",
      "9577\n",
      "9578\n",
      "9579\n",
      "9580\n",
      "9581\n",
      "9582\n",
      "9583\n",
      "9584\n",
      "9585\n",
      "9586\n",
      "9587\n",
      "9588\n",
      "9589\n",
      "9590\n",
      "9591\n",
      "9592\n",
      "9593\n",
      "9594\n",
      "9595\n",
      "9596\n",
      "9597\n",
      "9598\n",
      "9599\n",
      "9600\n",
      "9601\n",
      "9602\n",
      "9603\n",
      "9604\n",
      "9605\n",
      "9606\n",
      "9607\n",
      "9608\n",
      "9609\n",
      "9610\n",
      "9611\n",
      "9612\n",
      "9613\n",
      "9614\n",
      "9615\n",
      "9616\n",
      "9617\n",
      "9618\n",
      "9619\n",
      "9620\n",
      "9621\n",
      "9622\n",
      "9623\n",
      "9624\n",
      "9625\n",
      "9626\n",
      "9627\n",
      "9628\n",
      "9629\n",
      "9630\n",
      "9631\n",
      "9632\n",
      "9633\n",
      "9634\n",
      "9635\n",
      "9636\n",
      "9637\n",
      "9638\n",
      "9639\n",
      "9640\n",
      "9641\n",
      "9642\n",
      "9643\n",
      "9644\n",
      "9645\n",
      "9646\n",
      "9647\n",
      "9648\n",
      "9649\n",
      "9650\n",
      "9651\n",
      "9652\n",
      "9653\n",
      "9654\n",
      "9655\n",
      "9656\n",
      "9657\n",
      "9658\n",
      "9659\n",
      "9660\n",
      "9661\n",
      "9662\n",
      "9663\n",
      "9664\n",
      "9665\n",
      "9666\n",
      "9667\n",
      "9668\n",
      "9669\n",
      "9670\n",
      "9671\n",
      "9672\n",
      "9673\n",
      "9674\n",
      "9675\n",
      "9676\n",
      "9677\n",
      "9678\n",
      "9679\n",
      "9680\n",
      "9681\n",
      "9682\n",
      "9683\n",
      "9684\n",
      "9685\n",
      "9686\n",
      "9687\n",
      "9688\n",
      "9689\n",
      "9690\n",
      "9691\n",
      "9692\n",
      "9693\n",
      "9694\n",
      "9695\n",
      "9696\n",
      "9697\n",
      "9698\n",
      "9699\n",
      "9700\n",
      "9701\n",
      "9702\n",
      "9703\n",
      "9704\n",
      "9705\n",
      "9706\n",
      "9707\n",
      "9708\n",
      "9709\n",
      "9710\n",
      "9711\n",
      "9712\n",
      "9713\n",
      "9714\n",
      "9715\n",
      "9716\n",
      "9717\n",
      "9718\n",
      "9719\n",
      "9720\n",
      "9721\n",
      "9722\n",
      "9723\n",
      "9724\n",
      "9725\n",
      "9726\n",
      "9727\n",
      "9728\n",
      "9729\n",
      "9730\n",
      "9731\n",
      "9732\n",
      "9733\n",
      "9734\n",
      "9735\n",
      "9736\n",
      "9737\n",
      "9738\n",
      "9739\n",
      "9740\n",
      "9741\n",
      "9742\n",
      "9743\n",
      "9744\n",
      "9745\n",
      "9746\n",
      "9747\n",
      "9748\n",
      "9749\n",
      "9750\n",
      "9751\n",
      "9752\n",
      "9753\n",
      "9754\n",
      "9755\n",
      "9756\n",
      "9757\n",
      "9758\n",
      "9759\n",
      "9760\n",
      "9761\n",
      "9762\n",
      "9763\n",
      "9764\n",
      "9765\n",
      "9766\n",
      "9767\n",
      "9768\n",
      "9769\n",
      "9770\n",
      "9771\n",
      "9772\n",
      "9773\n",
      "9774\n",
      "9775\n",
      "9776\n",
      "9777\n",
      "9778\n",
      "9779\n",
      "9780\n",
      "9781\n",
      "9782\n",
      "9783\n",
      "9784\n",
      "9785\n",
      "9786\n",
      "9787\n",
      "9788\n",
      "9789\n",
      "9790\n",
      "9791\n",
      "9792\n",
      "9793\n",
      "9794\n",
      "9795\n",
      "9796\n",
      "9797\n",
      "9798\n",
      "9799\n",
      "9800\n",
      "9801\n",
      "9802\n",
      "9803\n",
      "9804\n",
      "9805\n",
      "9806\n",
      "9807\n",
      "9808\n",
      "9809\n",
      "9810\n",
      "9811\n",
      "9812\n",
      "9813\n",
      "9814\n",
      "9815\n",
      "9816\n",
      "9817\n",
      "9818\n",
      "9819\n",
      "9820\n",
      "9821\n",
      "9822\n",
      "9823\n",
      "9824\n",
      "9825\n",
      "9826\n",
      "9827\n",
      "9828\n",
      "9829\n",
      "9830\n",
      "9831\n",
      "9832\n",
      "9833\n",
      "9834\n",
      "9835\n",
      "9836\n",
      "9837\n",
      "9838\n",
      "9839\n",
      "9840\n",
      "9841\n",
      "9842\n",
      "9843\n",
      "9844\n",
      "9845\n",
      "9846\n",
      "9847\n",
      "9848\n",
      "9849\n",
      "9850\n",
      "9851\n",
      "9852\n",
      "9853\n",
      "9854\n",
      "9855\n",
      "9856\n",
      "9857\n",
      "9858\n",
      "9859\n",
      "9860\n",
      "9861\n",
      "9862\n",
      "9863\n",
      "9864\n",
      "9865\n",
      "9866\n",
      "9867\n",
      "9868\n",
      "9869\n",
      "9870\n",
      "9871\n",
      "9872\n",
      "9873\n",
      "9874\n",
      "9875\n",
      "9876\n",
      "9877\n",
      "9878\n",
      "9879\n",
      "9880\n",
      "9881\n",
      "9882\n",
      "9883\n",
      "9884\n",
      "9885\n",
      "9886\n",
      "9887\n",
      "9888\n",
      "9889\n",
      "9890\n",
      "9891\n",
      "9892\n",
      "9893\n",
      "9894\n",
      "9895\n",
      "9896\n",
      "9897\n",
      "9898\n",
      "9899\n",
      "9900\n",
      "9901\n",
      "9902\n",
      "9903\n",
      "9904\n",
      "9905\n",
      "9906\n",
      "9907\n",
      "9908\n",
      "9909\n",
      "9910\n",
      "9911\n",
      "9912\n",
      "9913\n",
      "9914\n",
      "9915\n",
      "9916\n",
      "9917\n",
      "9918\n",
      "9919\n",
      "9920\n",
      "9921\n",
      "9922\n",
      "9923\n",
      "9924\n",
      "9925\n",
      "9926\n",
      "9927\n",
      "9928\n",
      "9929\n",
      "9930\n",
      "9931\n",
      "9932\n",
      "9933\n",
      "9934\n",
      "9935\n",
      "9936\n",
      "9937\n",
      "9938\n",
      "9939\n",
      "9940\n",
      "9941\n",
      "9942\n",
      "9943\n",
      "9944\n",
      "9945\n",
      "9946\n",
      "9947\n",
      "9948\n",
      "9949\n",
      "9950\n",
      "9951\n",
      "9952\n",
      "9953\n",
      "9954\n",
      "9955\n",
      "9956\n",
      "9957\n",
      "9958\n",
      "9959\n",
      "9960\n",
      "9961\n",
      "9962\n",
      "9963\n",
      "9964\n",
      "9965\n",
      "9966\n",
      "9967\n",
      "9968\n",
      "9969\n",
      "9970\n",
      "9971\n",
      "9972\n",
      "9973\n",
      "9974\n",
      "9975\n",
      "9976\n",
      "9977\n",
      "9978\n",
      "9979\n",
      "9980\n",
      "9981\n",
      "9982\n",
      "9983\n",
      "9984\n",
      "9985\n",
      "9986\n",
      "9987\n",
      "9988\n",
      "9989\n",
      "9990\n",
      "9991\n",
      "9992\n",
      "9993\n",
      "9994\n",
      "9995\n",
      "9996\n",
      "9997\n",
      "9998\n",
      "9999\n",
      "Accuracy: 99.96%\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(model, dataloader, tokenizer, device='cuda', max_samples=100):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            print(total)\n",
    "            # Generate predictions\n",
    "            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=1024)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            for output, label in zip(outputs, labels):\n",
    "                # Trim padding tokens (assuming padding token is 1)\n",
    "                output_trimmed = output[output != 1][1:]\n",
    "                label_trimmed = label[label != 1]\n",
    "\n",
    "                # Check if the output sequence matches the label\n",
    "                if torch.equal(output_trimmed, label_trimmed):\n",
    "                    correct += 1\n",
    "\n",
    "                total += 1\n",
    "                if total >= max_samples:\n",
    "                    break\n",
    "\n",
    "            if total >= max_samples:\n",
    "                break\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Example usage\n",
    "accuracy1 = calculate_accuracy(model, ood_dataloader, tokenizer, max_samples=10000)\n",
    "print(f\"Accuracy: {accuracy1:.2%}\")\n",
    "accuracy2 = calculate_accuracy(model, train_dataloader, tokenizer, max_samples=10)\n",
    "print(f\"Accuracy: {accuracy2:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='617' max='3125000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    617/3125000 02:48 < 237:12:14, 3.66 it/s, Epoch 0.00/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1640\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1636\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1637\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1638\u001b[0m         )\n\u001b[0;32m-> 1640\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1659\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1508\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1505\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1508\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1114\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1107\u001b[0m             encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1108\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             output_attentions,\n\u001b[1;32m   1112\u001b[0m         )\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1114\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:567\u001b[0m, in \u001b[0;36mBartEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m        returned tensors for more detail.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 567\u001b[0m hidden_states, attn_weights, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    574\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:449\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    446\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# get query proj\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m(hidden_states)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# get key, value proj\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# `past_key_value[0].shape[2] == key_value_states.shape[1]`\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# is checking that the `sequence_length` of the `past_key_value` is the same as\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# the provided `key_value_states` to support prefix tuning\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    455\u001b[0m     is_cross_attention\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m past_key_value[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m key_value_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    458\u001b[0m ):\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# reuse k,v, cross_attentions\u001b[39;00m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1718\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/14*14.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the dataset to a pickle file\n",
    "with open('train_dataset_14.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    trainer.train()\n",
    "    \n",
    "    accuracy = calculate_accuracy(model, train_dataloader, tokenizer)\n",
    "    accuracies.append((epoch + 1, accuracy))\n",
    "    print(f\"Epoch {epoch + 1} Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs, acc_values = zip(*accuracies)\n",
    "plt.plot([epoch * 25 for epoch in epochs], acc_values)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('3 Digits + 3 Digits')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4, 5, 6, 7, 8, 9) (0.0, 0.043, 0.115, 0.683, 0.905, 0.934, 0.969, 0.994, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(epochs, acc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 3 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 3 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 5 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 5 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 5 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 5 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 -1 5 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 -1 5 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 -1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 -1 5 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 -1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 -1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 -1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "def predict_with_input(model, tokenizer, input_text, device='cuda'):\n",
    "    model.eval()\n",
    "\n",
    "    # Encode the input text\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        return_tensors='pt',\n",
    "        padding='max_length',  # or 'longest' depending on your use case\n",
    "        max_length=1024,  # Adjust based on your model's requirements\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate predictions\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=1024)\n",
    "    \n",
    "    # Decode the output\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded_output\n",
    "\n",
    "# Example usage\n",
    "input_text = \"1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\"\n",
    "prediction = predict_with_input(model, tokenizer, input_text)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      "Label: 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 10 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 3 7 0 0 0 0 0 0 0 0 0 0 0 0 0 3 10 7 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 3 7 1 0 0 0 0 0 0 0 0 0 0 0 0 3 10 7 15 0 0 0 0 0 0 0 0 0 0 0 0 -1 5 3 7 1 1 0 0 0 0 0 0 0 0 0 0 0 3 10 7 15 4 0 0 0 0 0 0 0 0 0 0 0 -1 5 3 7 1 1 3 0 0 0 0 0 0 0 0 0 0 3 10 7 15 4 13 0 0 0 0 0 0 0 0 0 0 -1 5 3 7 1 1 3 10 0 0 0 0 0 0 0 0 0 3 10 7 15 4 13 5 0 0 0 0 0 0 0 0 0 -1 5 3 7 1 1 3 10 4 0 0 0 0 0 0 0 0 3 10 7 15 4 13 5 12 0 0 0 0 0 0 0 0 -1 5 3 7 1 1 3 10 4 1 0 0 0 0 0 0 0 3 10 7 15 4 13 5 12 1 0 0 0 0 0 0 0 -1 5 3 7 1 1 3 10 4 1 9 0 0 0 0 0 0 3 10 7 15 4 13 5 12 1 5 0 0 0 0 0 0 -1 5 3 7 1 1 3 10 4 1 9 2 0 0 0 0 0 3 10 7 15 4 13 5 12 1 5 3 0 0 0 0 0 -1 5 3 7 1 1 3 10 4 1 9 2 5 0 0 0 0 3 10 7 15 4 13 5 12 1 5 3 5 0 0 0 0 -1 5 3 7 1 1 3 10 4 1 9 2 5 1 0 0 0 3 10 7 15 4 13 5 12 1 5 3 5 13 0 0 0 -1 5 3 7 1 1 3 10 4 1 9 2 5 1 7 0 0 3 10 7 15 4 13 5 12 1 5 3 5 13 10 0 0 -1 5 3 7 1 1 3 10 4 1 9 2 5 1 7 15 0 3 10 7 15 4 13 5 12 1 5 3 5 13 10 6 0 -1 5 3 7 1 1 3 10 4 1 9 2 5 1 7 15 10 3 10 7 15 4 13 5 12 1 5 3 5 13 10 6 6 -1 a 5 b 3 c 7 d 1 e 1 f 3 g 10 h 4 i 1 j 9 k 2 l 5 m 1 n 7 o 15 p 10 -1 a 3 b 10 c 7 d 15 e 4 f 13 g 5 h 12 i 1 j 5 k 3 l 5 m 13 n 10 o 6 p 6 -1 a 15 b 30 c 49 d 15 e 4 f 39 g 50 h 48 i 1 j 45 k 6 l 25 m 13 n 70 o 90 p 60 -1 15 30 49 15 4 39 50 48 1 45 6 25 13 70 90 60 -1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 3 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 3 2 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 3 2 1 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 3 2 1 1 0 0 0 0 0 -1 1 1 1 0 1 0 1 3 2 1 1 1 0 0 0 0 -1 1 1 1 0 1 0 1 3 2 1 1 1 0 0 0 0 -1 1 1 1 0 1 0 1 3 2 1 1 1 0 1 0 0 -1 1 1 1 0 1 0 1 3 2 1 1 1 0 1 1 0 -1 1 1 1 0 1 0 1 3 2 1 1 1 0 1 1 0 -1\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the data loader\n",
    "for batch in train_dataloader:\n",
    "    # Extract the input_ids and labels from the batch\n",
    "    input_ids = batch['input_ids'][0]  # Get the first example in the batch\n",
    "    labels = batch['labels'][0]  # Get the corresponding label\n",
    "\n",
    "    # Decode and print the input sequence\n",
    "    input_text = tokenizer.decode(input_ids, skip_special_tokens=True).strip()\n",
    "    print(f\"Input: {input_text}\")\n",
    "\n",
    "    # Decode and print the label sequence\n",
    "    label_text = tokenizer.decode(labels, skip_special_tokens=True).strip()\n",
    "    print(f\"Label: {label_text}\")\n",
    "    \n",
    "    # Break after the first example\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded: '0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 -1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 -1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 -1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 -1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 -1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 -1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n",
      "Decoded: '0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 -1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0' | Input: '0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure dataloader is not shuffled\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     14\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m exists \u001b[38;5;241m=\u001b[39m \u001b[43minput_in_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput is in dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexists\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m, in \u001b[0;36minput_in_dataloader\u001b[0;34m(input_text, dataloader, tokenizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m         decoded_data \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoded: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoded_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | Input: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m decoded_data \u001b[38;5;241m==\u001b[39m input_text:\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4034\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   4032\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 4034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4038\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4039\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/tokenization_utils.py:1072\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode\u001b[39m(\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1064\u001b[0m     token_ids: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1069\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_use_source_tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_source_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1072\u001b[0m     filtered_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_ids_to_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m     legacy_added_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_added_tokens_encoder\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_tokens) \u001b[38;5;241m|\u001b[39m {\n\u001b[1;32m   1074\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(token) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m   1075\u001b[0m     }\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;66;03m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# we need to build string separately for added tokens and byte-level tokens\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# cf. https://github.com/huggingface/transformers/issues/1133\u001b[39;00m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/tokenization_utils.py:1048\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m   1047\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index)\n\u001b[0;32m-> 1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_special_tokens \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_ids\u001b[49m:\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_added_tokens_decoder:\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1363\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_ids\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_special_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;124;03m    `List[int]`: List the ids of the special tokens(`'<unk>'`, `'<cls>'`, etc.) mapped to class attributes.\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m     all_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens\u001b[49m\n\u001b[1;32m   1364\u001b[0m     all_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(all_toks)\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_ids\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1355\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_special_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    `List[str]`: A list of the unique special tokens (`'<unk>'`, `'<cls>'`, ..., etc.).\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \n\u001b[1;32m   1353\u001b[0m \u001b[38;5;124;03m    Convert tokens of `tokenizers.AddedToken` type to string.\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m     all_toks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens_extended\u001b[49m]\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_toks\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1339\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_tokens_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m all_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1338\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m-> 1339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial_tokens_map_extended\u001b[49m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m   1341\u001b[0m         tokens_to_add \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m value \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(token) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen]\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1322\u001b[0m, in \u001b[0;36mSpecialTokensMixin.special_tokens_map_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1320\u001b[0m set_attr \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSPECIAL_TOKENS_ATTRIBUTES:\n\u001b[0;32m-> 1322\u001b[0m     attr_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attr_value:\n\u001b[1;32m   1324\u001b[0m         set_attr[attr] \u001b[38;5;241m=\u001b[39m attr_value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def input_in_dataloader(input_text, dataloader, tokenizer):\n",
    "    for batch in dataloader:\n",
    "        for input_ids in batch['input_ids']:\n",
    "            decoded_data = tokenizer.decode(input_ids, skip_special_tokens=True).strip()\n",
    "            print(f\"Decoded: '{decoded_data}' | Input: '{input_text}'\")\n",
    "            if decoded_data == input_text:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Ensure dataloader is not shuffled\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Example usage\n",
    "input_text = \"0 1 1 1 0 0 0 0 -1 1 0 1 0 0 0 0 0\"\n",
    "exists = input_in_dataloader(input_text, train_dataloader, tokenizer)\n",
    "print(f\"Input is in dataset: {exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50258, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000000 * 11010000 = 110010000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def binary_multiplication(model, tokenizer, bin_a, bin_b):\n",
    "    model.eval()\n",
    "    \n",
    "    # Pad binary numbers (assuming pad_binary is a defined function)\n",
    "    padded_a = pad_binary(bin_a)\n",
    "    padded_b = pad_binary(bin_b)\n",
    "    \n",
    "    # Compute FFT with depth information (assuming these functions are defined)\n",
    "    fft_number1, tree_dict1 = compute_fft_with_tree(padded_a)\n",
    "    fft_number2, tree_dict2 = compute_fft_with_tree(padded_b)\n",
    "    \n",
    "    # Compute the convolution of the FFTs\n",
    "    multiplication = np.multiply(fft_number1, fft_number2)\n",
    "    \n",
    "    # Compute iFFT with depth information\n",
    "    inverse, ifft_tree_dict = compute_ifft_with_tree(multiplication)\n",
    "    inverse = np.array(inverse).real.round().astype(int)\n",
    "    \n",
    "    # Prepare depth columns for FFT1\n",
    "    fft1_depth_text = \"\"\n",
    "    max_depth1 = max(k[0] for k in tree_dict1.keys())\n",
    "    for depth in range(max_depth1, -1, -1):\n",
    "        nodes = [np.round(tree_dict1.get((depth, i), []), 2).tolist() for i in range(2**depth)]\n",
    "        fft1_depth_text += f\", FFT1_depth_{depth}: {nodes}\"\n",
    "    \n",
    "    # Prepare depth columns for FFT2\n",
    "    fft2_depth_text = \"\"\n",
    "    max_depth2 = max(k[0] for k in tree_dict2.keys())\n",
    "    for depth in range(max_depth2, -1, -1):\n",
    "        nodes = [np.round(tree_dict2.get((depth, i), []), 2).tolist() for i in range(2**depth)]\n",
    "        fft2_depth_text += f\", FFT2_depth_{depth}: {nodes}\"\n",
    "    \n",
    "    # Prepare depth columns for iFFT\n",
    "    ifft_depth_text = \"\"\n",
    "    max_depth_ifft = max(k[0] for k in ifft_tree_dict.keys())\n",
    "    for depth in range(max_depth_ifft, -1, -1):\n",
    "        nodes = [np.round(ifft_tree_dict.get((depth, i), []), 2).tolist() for i in range(2**depth)]\n",
    "        ifft_depth_text += f\", ifft_depth_{depth}: {nodes}\"\n",
    "    \n",
    "    # Construct the input text\n",
    "    input_text = (\n",
    "            f\"{bin_a}, \"\n",
    "            f\"{bin_b}, \"\n",
    "        )\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=MAX_LENGTH, padding='max_length', truncation=True)\n",
    "    input_ids = inputs['input_ids'].to('cuda')\n",
    "    attention_mask = inputs['attention_mask'].to('cuda')\n",
    "    \n",
    "    # Generate the output text\n",
    "    with torch.no_grad():\n",
    "        beam_output = model.generate(input_ids, attention_mask = attention_mask, max_length=512, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "        output = tokenizer.decode(beam_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example\n",
    "bin_a = 11000000\n",
    "bin_b = 11010000\n",
    "result = binary_multiplication(model, tokenizer, bin_a, bin_b)\n",
    "print(f\"{bin_a} * {bin_b} = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 model saved to ../temp/t5_base_model_without_FFT.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../temp/t5_base_model_without_FFT.pth\"\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"T5 model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11110110 10010111 110001100 110001101\n",
      "10100000 10001111 100101111 100101111\n",
      "00001111 10010101 10100001 10100100\n",
      "10010001 01011101 11100011 11101110\n",
      "01110111 11001001 101000011 101000000\n",
      "10111100 01101010 100101100 100100110\n",
      "00111111 01100111 10100001 10100110\n",
      "11000110 10011111 101100111 101100101\n",
      "00000011 10101000 10110001 10101011\n",
      "11111000 00001111 11111111 100000111\n",
      "01011011 00110100 1110111 10001111\n",
      "00111000 11100100 100011101 100011100\n",
      "11111101 01000010 100111111 100111111\n",
      "11011001 00110100 100001111 100001101\n",
      "01001101 11111001 101001000 101000110\n",
      "01110000 10111001 100101111 100101001\n",
      "00111001 00001011 111111 1000100\n",
      "00111100 11110011 100110000 100101111\n",
      "10011111 10011011 100111111 100111010\n",
      "01100110 01101001 11001111 11001111\n",
      "01001110 00100111 1110111 1110101\n",
      "10000000 00001111 10001111 10001111\n",
      "01111011 01110110 10111111 11110001\n",
      "11001000 10111000 110000100 110000000\n",
      "00100100 01010010 1111100 1110110\n",
      "00111001 11011011 100001101 100010100\n",
      "01011100 10111010 100010111 100010110\n",
      "00110101 11011011 100000101 100010000\n",
      "11011110 01001000 101001101 100100110\n",
      "01010101 10000111 11011011 11011100\n",
      "10001101 11010010 101100111 101011111\n",
      "11010010 01000010 100010110 100010100\n",
      "10100100 01111101 100100000 100100001\n",
      "00000001 11011010 11011101 11011011\n",
      "10000110 11111010 101111111 110000000\n",
      "01101010 01011101 10111111 11000111\n",
      "01101001 01110010 11011111 11011011\n",
      "01111100 01011110 11010011 11011010\n",
      "11000011 00001110 11001111 11010001\n",
      "11100010 01111011 101011011 101011101\n",
      "01010100 11010010 100101111 100100110\n",
      "01111110 11101111 101101000 101101101\n",
      "10010110 00111000 11000101 11001110\n",
      "10000100 11110101 101110111 101111001\n",
      "01010000 01000110 10010101 10010110\n",
      "10001101 01111111 100001100 100001100\n",
      "01011000 01101000 11000101 11000000\n",
      "01000111 01001000 10010101 10001111\n",
      "10110101 11101100 110100001 110100001\n",
      "11000001 01011000 100011011 100011001\n",
      "00110101 11110110 100011101 100101011\n",
      "01100000 10010101 11110111 11110101\n",
      "10100111 01000001 11101100 11101000\n",
      "11111100 10010001 110011111 110001101\n",
      "01011010 01110001 11001011 11001011\n",
      "00011011 11011000 11110111 11110011\n",
      "01011001 01111001 11001101 11010010\n",
      "10100101 10001000 100110000 100101101\n",
      "01010101 10100110 100001011 11111011\n",
      "01110011 10010011 100000101 100000110\n",
      "11110001 10110000 110100000 110100001\n",
      "11011010 10100000 110000001 101111010\n",
      "11101110 01001000 100111110 100110110\n",
      "01110100 01111110 11110111 11110010\n",
      "01110111 00110011 10010111 10101010\n",
      "01110001 11100010 101010100 101010011\n",
      "10100110 10000110 100101100 100101100\n",
      "11001000 11011011 110100001 110100011\n",
      "00000110 01101100 1110111 1110010\n",
      "00100011 11101011 100001110 100001110\n",
      "00011100 10100001 10111111 10111101\n",
      "10000101 10000111 100010100 100001100\n",
      "00101110 00111111 1101111 1101101\n",
      "11111111 11101011 111101100 111101010\n",
      "11111001 01001001 101000011 101000010\n",
      "01100111 00110000 10010101 10010111\n",
      "11010011 01010001 100101111 100100100\n",
      "10011100 11111101 110010101 110011001\n",
      "10011110 11101111 110000111 110001101\n",
      "01000101 00011010 1011110 1011111\n",
      "00001011 00110011 111100 111110\n",
      "10101011 10001110 100110101 100111001\n",
      "00010110 10101011 10111111 11000001\n",
      "00110011 00001101 111111 1000000\n",
      "11001001 00000111 11001111 11010000\n",
      "01101011 01011001 11000101 11000100\n",
      "01000000 01101111 10110011 10101111\n",
      "01010001 11000101 100010111 100010110\n",
      "11010011 11000101 110010101 110011000\n",
      "10000000 10100011 100100000 100100011\n",
      "00011000 00111100 1001101 1010100\n",
      "11101110 01010011 101000011 101000001\n",
      "00011111 00011100 1000101 111011\n",
      "11110000 01000110 100111011 100110110\n",
      "10111010 11000101 101111111 101111111\n",
      "10101011 11000110 101110000 101110001\n",
      "00100011 00110000 1011011 1010011\n",
      "11111011 10000000 101111111 101111011\n",
      "00110011 11100010 100011011 100010101\n",
      "01111100 10111111 100111011 100111011\n",
      "Model accuracy: 11.00%\n"
     ]
    }
   ],
   "source": [
    "def generate_test_examples_from_df(dataframe):\n",
    "    examples = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        bin_a = row['First Number']\n",
    "        bin_b = row['Second Number']\n",
    "        examples.append((bin_a, bin_b))\n",
    "    return examples\n",
    "\n",
    "def compute_ground_truth(bin_a, bin_b):\n",
    "    int_a = int(bin_a, 2)\n",
    "    int_b = int(bin_b, 2)\n",
    "    result = int_a + int_b\n",
    "    return bin(result)[2:]  # Convert to binary string and remove '0b' prefix\n",
    "\n",
    "def calculate_accuracy(model, tokenizer, test_examples):\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for bin_a, bin_b in test_examples:\n",
    "        predicted_result = binary_multiplication(model, tokenizer, bin_a, bin_b)\n",
    "    \n",
    "        if predicted_result != '00000000':\n",
    "            predicted_result = predicted_result.lstrip('0')\n",
    "        else:\n",
    "            predicted_result = '0'\n",
    "        predicted_result = predicted_result.rstrip(' ')\n",
    "        ground_truth = compute_ground_truth(bin_a, bin_b)    \n",
    "        print(bin_a, bin_b, predicted_result, ground_truth)   \n",
    "\n",
    "        # Compare the predicted result with the ground truth\n",
    "        if predicted_result == ground_truth:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / len(test_examples)\n",
    "    return accuracy\n",
    "\n",
    "# Example usage\n",
    "test_examples = generate_test_examples_from_df(dataset_df.sample(n=100, random_state=42))  # Generate 100 test examples\n",
    "accuracy = calculate_accuracy(model, tokenizer, test_examples)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m examples\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Generate unique test examples with results\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m unique_test_examples \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_unique_test_examples_with_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# test_df = pd.DataFrame(unique_test_examples, columns=['First Number', 'Second Number', 'Final Result'])\u001b[39;00m\n\u001b[1;32m     24\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m calculate_accuracy(model, tokenizer, unique_test_examples)\n",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mgenerate_unique_test_examples_with_results\u001b[0;34m(dataframe, num_examples)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m<\u001b[39m num_examples:\n\u001b[1;32m      9\u001b[0m     bin_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m15\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m04b\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Generate random 4-bit binary number\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     bin_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m04b\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (bin_a, bin_b) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m existing_pairs:\n\u001b[1;32m     12\u001b[0m         result \u001b[38;5;241m=\u001b[39m compute_ground_truth(bin_a, bin_b)\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/random.py:370\u001b[0m, in \u001b[0;36mRandom.randint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.10/random.py:303\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# This code is a bit messy to make it fast for the\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# common case while still doing adequate error checking.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     istart \u001b[38;5;241m=\u001b[39m \u001b[43m_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     istart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(start)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def generate_unique_test_examples_with_results(dataframe, num_examples=100):\n",
    "    existing_pairs = set(zip(dataframe['First Number'], dataframe['Second Number']))\n",
    "    examples = []\n",
    "\n",
    "    while len(examples) < num_examples:\n",
    "        bin_a = format(random.randint(0, 15), '04b')  # Generate random 4-bit binary number\n",
    "        bin_b = format(random.randint(0, 15), '04b')\n",
    "        if (bin_a, bin_b) not in existing_pairs:\n",
    "            result = compute_ground_truth(bin_a, bin_b)\n",
    "            examples.append((bin_a, bin_b))\n",
    "            existing_pairs.add((bin_a, bin_b))  # Ensure uniqueness\n",
    "\n",
    "    return examples\n",
    "\n",
    "# Generate unique test examples with results\n",
    "unique_test_examples = generate_unique_test_examples_with_results(dataset_df, num_examples=100)\n",
    "\n",
    "# Convert to DataFrame\n",
    "# test_df = pd.DataFrame(unique_test_examples, columns=['First Number', 'Second Number', 'Final Result'])\n",
    "\n",
    "accuracy = calculate_accuracy(model, tokenizer, unique_test_examples)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
